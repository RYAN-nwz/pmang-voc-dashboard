# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import re
import os # í°íŠ¸ ê²½ë¡œë¥¼ ìœ„í•´ os ëª¨ë“ˆ ì¶”ê°€
import base64 # ë¡œê³  ì´ë¯¸ì§€ë¥¼ ìœ„í•´ base64 ëª¨ë“ˆ ì¶”ê°€

# --- 1. ê¸°ë³¸ ì„¤ì • ---
# Google Sheets ë° í˜ì´ì§€ ì„¤ì •
# SPREADSHEET_IDëŠ” ìƒìˆ˜ë¡œ ìœ ì§€í•˜ê³ , ì¸ì¦ ì •ë³´ëŠ” st.secretsìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
SPREADSHEET_ID = "1rgR21yUBtKSJKE4KYdBvoZzDU-0jZ_wLb6Tqc_zS7RM"
LOGO_IMAGE = "images/pmang_logo.png"

st.set_page_config(page_title="ì›¹ë³´ë“œ VOC ëŒ€ì‹œë³´ë“œ", page_icon=LOGO_IMAGE, layout="wide")

# L2 íƒœê·¸ë¥¼ L1 ëŒ€ë¶„ë¥˜ë¡œ ë§¤í•‘í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬
L2_TO_L1_MAPPING = {
    'ë¡œê·¸ì¸/ì¸ì¦': 'ê³„ì •', 'ì •ë³´ ê´€ë¦¬': 'ê³„ì •',
    'ê¸°ìˆ  ì˜¤ë¥˜': 'ì‹œìŠ¤í…œ/í™˜ê²½',
    'ê²°ì œ ì˜¤ë¥˜/ë¯¸ì§€ê¸‰': 'ì¬í™”/ê²°ì œ', 'í™˜ë¶ˆ/ì²­ì•½ì² íšŒ': 'ì¬í™”/ê²°ì œ', 'ì¬í™” ì†Œì‹¤/ì˜¤ë¥˜': 'ì¬í™”/ê²°ì œ',
    'í´ë˜ìŠ¤/êµ¬ë… ìƒí’ˆ': 'ì¬í™”/ê²°ì œ', 'ì¬í™” ì •ì±…/í•œë„': 'ì¬í™”/ê²°ì œ',
    'ë°¸ëŸ°ìŠ¤/ë¶ˆë§Œ (íŒ¨ëª°ë¦¼)': 'ê²Œì„ í”Œë ˆì´', 'ì½˜í…ì¸  ì˜¤ë¥˜/ë¬¸ì˜': 'ê²Œì„ í”Œë ˆì´', 'í† ë„ˆë¨¼íŠ¸/ëŒ€íšŒ': 'ê²Œì„ í”Œë ˆì´',
    'ì ë ¹ì „/ê±°ì ì „': 'ê²Œì„ í”Œë ˆì´', 'ë­í‚¹í˜ìŠ¤íƒ€': 'ê²Œì„ í”Œë ˆì´', 'ì—°ìŠ¹ì±Œë¦°ì§€': 'ê²Œì„ í”Œë ˆì´', 'íŒ¨ë°€ë¦¬ê²Œì„': 'ê²Œì„ í”Œë ˆì´',
    'ê´‘ê³ /ë¬´ë£Œì¶©ì „ì†Œ': 'ì´ë²¤íŠ¸/í˜œíƒ', 'ì´ë²¤íŠ¸': 'ì´ë²¤íŠ¸/í˜œíƒ',
    'ë¹„ë§¤ë„ˆ/ìš•ì„¤ ì‹ ê³ ': 'ë¶ˆëŸ‰ ì´ìš©ì', 'ì œì¬ ë¬¸ì˜': 'ë¶ˆëŸ‰ ì´ìš©ì',
    'ì½˜í…ì¸ /ì‹œìŠ¤í…œ ê±´ì˜': 'ì •ì±…/ê±´ì˜ (VOC)', 'ìš´ì˜/ì •ì±… ê±´ì˜': 'ì •ì±…/ê±´ì˜ (VOC)',
    'ë‹¨ìˆœ ë¬¸ì˜/ë¯¸ë¶„ë¥˜': 'ê¸°íƒ€'
}

# --- 2. ë°ì´í„° ì²˜ë¦¬ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def classify_game(category):
    """'ì ‘ìˆ˜ ì¹´í…Œê³ ë¦¬'ì—ì„œ í‘œì¤€ ê²Œì„ ì´ë¦„ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    if pd.isna(category): return "ê¸°íƒ€"
    # [ê°œì„ ] ëª¨ë“  ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ì—¬ í‚¤ì›Œë“œ ë§¤ì¹­ ì•ˆì •ì„± ê°•í™”
    processed_category = re.sub(r'[^a-z0-9ã„±-ã…ã…-ã…£ê°€-í£]', '', str(category).lower())
    
    # [ìˆ˜ì •] ê°€ì¥ êµ¬ì²´ì ì¸ ê²Œì„ë¶€í„° í™•ì¸í•˜ì—¬ ì¤‘ë³µ ë¶„ë¥˜ë¥¼ ë°©ì§€ (ë§¤ìš° ì¤‘ìš”)
    # 1. ì‡¼ë‹¤ìš´í™€ë¤ í™•ì¸
    if "ì‡¼ë‹¤ìš´í™€ë¤" in processed_category or "showdown" in processed_category: 
        return "ì‡¼ë‹¤ìš´í™€ë¤"
    
    # 2. ë‰´ë² ê°€ìŠ¤/ì¹´ì§€ë…¸êµ° í™•ì¸
    if "ë‰´ë² ê°€ìŠ¤" in processed_category or "newvegas" in processed_category or "ì¹´ì§€ë…¸êµ°" in processed_category: 
        return "ë‰´ë² ê°€ìŠ¤"
    
    # 3. ê¸°íƒ€ ê²Œì„ë“¤ í™•ì¸
    if "ë‰´ë§ê³ " in processed_category or "newmatgo" in processed_category: 
        return "ë‰´ë§ê³ "
    if "ì„¯ë‹¤" in processed_category or "sutda" in processed_category: 
        return "ì„¯ë‹¤"
    
    # 4. ìœ„ì˜ ëª¨ë“  íŠ¹ì • ê²Œì„ì´ ì•„ë‹ ê²½ìš°ì—ë§Œ ì¼ë°˜ 'í¬ì»¤'ë¡œ ë¶„ë¥˜
    if "í¬ì»¤" in processed_category or "poker" in processed_category: 
        return "í¬ì»¤"

    return "ê¸°íƒ€"

def classify_platform(category):
    """'ì ‘ìˆ˜ ì¹´í…Œê³ ë¦¬'ì—ì„œ í”Œë«í¼ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    if pd.isna(category): return "ê¸°íƒ€"
    # [ê°œì„ ] ëª¨ë“  ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ì—¬ í‚¤ì›Œë“œ ë§¤ì¹­ ì•ˆì •ì„± ê°•í™”
    processed_category = re.sub(r'[^a-z0-9ã„±-ã…ã…-ã…£ê°€-í£]', '', str(category).lower())

    if "forkakao" in processed_category or "fork" in processed_category: return "for kakao"
    if "mob" in processed_category or "ëª¨ë°”ì¼" in processed_category: return "MOB"
    if "pc" in processed_category: return "PC"
    return "ê¸°íƒ€"

def extract_gsn_usn(row):
    """'ë¬¸ì˜ë‚´ìš©' ë˜ëŠ” 'ê³ ê°ì •ë³´'ì—ì„œ GSN(ëª¨ë°”ì¼) ë˜ëŠ” USN(PC)ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    platform = row.get('í”Œë«í¼', '')
    
    if platform in ['MOB', 'for kakao']:
        inquiry_content = str(row.get('ë¬¸ì˜ë‚´ìš©', ''))
        gsn_match = re.search(r'íšŒì›ë²ˆí˜¸\s*:\s*(\d+)', inquiry_content)
        if gsn_match:
            return gsn_match.group(1)
            
    if platform == 'PC':
        customer_info = str(row.get('ê³ ê°ì •ë³´', ''))
        usn_match = re.search(r'\d+', customer_info)
        if usn_match:
            return usn_match.group(0)
            
    return ""

def extract_device_info(row):
    """'ë¬¸ì˜ë‚´ìš©'ì—ì„œ ê¸°ê¸°ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê±°ë‚˜ í”Œë«í¼ì— ë”°ë¼ PCë¡œ ì§€ì •í•˜ëŠ” í•¨ìˆ˜"""
    inquiry_content = str(row.get('ë¬¸ì˜ë‚´ìš©', ''))
    device_match = re.search(r'íœ´ëŒ€í°ê¸°ê¸°ì •ë³´\s*:\s*(\S+)', inquiry_content)
    if device_match:
        return device_match.group(1)
    
    platform = row.get('í”Œë«í¼', '')
    if platform == 'PC':
        return 'PC'
        
    return ""

def truncate_inquiry_content(text):
    """ë¬¸ì˜ ë‚´ìš©ì—ì„œ ì •í˜•í™”ëœ í…œí”Œë¦¿ ë¶€ë¶„ì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜"""
    if isinstance(text, str):
        return text.split("íšŒì›ë²ˆí˜¸ :")[0].strip()
    return ""


@st.cache_data(ttl=600)
def load_data():
    """Google Sheetsì—ì„œ ëª¨ë“  VOC ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    try:
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        
        # [ìˆ˜ì •] st.secretsë¥¼ ë¨¼ì € ì‹œë„í•˜ê³ , ì—†ì„ ê²½ìš° ë¡œì»¬ json íŒŒì¼ë¡œ fallback
        try:
            # ë°°í¬ í™˜ê²½ ë˜ëŠ” .streamlit/secrets.toml íŒŒì¼ì´ ì„¤ì •ëœ ê²½ìš°
            creds_dict = st.secrets["gcp_service_account"]
            creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        except (FileNotFoundError, KeyError):
            # ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œ service_account.json íŒŒì¼ ì‚¬ìš©
            SERVICE_ACCOUNT_FILE = "service_account.json"
            if os.path.exists(SERVICE_ACCOUNT_FILE):
                creds = ServiceAccountCredentials.from_json_keyfile_name(SERVICE_ACCOUNT_FILE, scope)
            else:
                st.error(f"ì¸ì¦ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .streamlit/secrets.toml íŒŒì¼ì„ ì„¤ì •í•˜ê±°ë‚˜, í”„ë¡œì íŠ¸ í´ë”ì— '{SERVICE_ACCOUNT_FILE}' íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
                return pd.DataFrame()

        gc = gspread.authorize(creds)
        
        spreadsheet = gc.open_by_key(SPREADSHEET_ID)
        worksheets = spreadsheet.worksheets()
        all_data = []
        
        for worksheet in worksheets:
            if worksheet.title.lower() not in ["sheet1", "template", "mapping"]:
                try:
                    data = worksheet.get_all_records()
                    if data:
                        for row in data: row["ë‚ ì§œ"] = worksheet.title
                        all_data.extend(data)
                except Exception: continue
        
        if not all_data: return pd.DataFrame()
        df = pd.DataFrame(all_data)
        
        required_cols = ["ì ‘ìˆ˜ ì¹´í…Œê³ ë¦¬", "ìƒë‹´ì œëª©", "ë¬¸ì˜ë‚´ìš©", "taglist"]
        if not all(col in df.columns for col in required_cols):
            st.error(f"í•„ìˆ˜ ì»¬ëŸ¼({required_cols})ì´ Google Sheetsì— ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        df.rename(columns={'taglist': 'L2 íƒœê·¸'}, inplace=True)
        df["ê²Œì„"] = df["ì ‘ìˆ˜ ì¹´í…Œê³ ë¦¬"].apply(classify_game)
        df["í”Œë«í¼"] = df["ì ‘ìˆ˜ ì¹´í…Œê³ ë¦¬"].apply(classify_platform)
        df["ë‚ ì§œ_dt"] = pd.to_datetime(df["ë‚ ì§œ"], format='%y%m%d', errors='coerce')
        df = df.dropna(subset=["ë‚ ì§œ_dt"])
        df['L1 íƒœê·¸'] = df['L2 íƒœê·¸'].map(L2_TO_L1_MAPPING).fillna('ê¸°íƒ€')
        
        df['GSN(USN)'] = df.apply(extract_gsn_usn, axis=1)
        df['ê¸°ê¸°ì •ë³´'] = df.apply(extract_device_info, axis=1)
        df['ë¬¸ì˜ë‚´ìš©_ìš”ì•½'] = df['ë¬¸ì˜ë‚´ìš©'].apply(truncate_inquiry_content)
        df['ê²€ìƒ‰ìš©_ë¬¸ì˜ë‚´ìš©'] = df['ë¬¸ì˜ë‚´ìš©_ìš”ì•½']
        
        return df

    except gspread.exceptions.SpreadsheetNotFound:
        st.error("Google Sheets ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. SPREADSHEET_IDë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# [ê¸°ëŠ¥ ì¶”ê°€] AI ìš”ì•½ ê¸°ëŠ¥ (ì‹œë®¬ë ˆì´ì…˜)
@st.cache_data(ttl=1800) # 30ë¶„ ìºì‹œ
def get_game_issue_summary(_game_name, game_data):
    """
    ì£¼ì–´ì§„ ê²Œì„ ë°ì´í„°ì—ì„œ ì£¼ìš” ì´ìŠˆë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
    (í˜„ì¬ëŠ” í•˜ë“œì½”ë”©ëœ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë©°, ì‹¤ì œ AI ì—°ë™ì´ í•„ìš”í•©ë‹ˆë‹¤.)
    """
    if game_data.empty:
        return {"title": "ë°ì´í„° ì—†ìŒ", "quote": "í•´ë‹¹ ê¸°ê°„ì— ìˆ˜ì§‘ëœ VOCê°€ ì—†ìŠµë‹ˆë‹¤."}

    # TODO: ì‹¤ì œ AI ì—°ë™ ì‹œ ì´ ë¶€ë¶„ì„ API í˜¸ì¶œ ë¡œì§ìœ¼ë¡œ ëŒ€ì²´
    # 1. game_dataì—ì„œ ê°€ì¥ ë¹ˆë„ê°€ ë†’ì€ 'L2 íƒœê·¸'ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    # 2. í•´ë‹¹ íƒœê·¸ì˜ VOC ë‚´ìš©(ë¬¸ì˜ë‚´ìš©_ìš”ì•½) ëª‡ ê°œë¥¼ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.
    # 3. ìƒ˜í”Œë§ëœ ë‚´ìš©ì„ AI ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ 'title', 'quote'ë¥¼ ìƒì„±í•˜ë„ë¡ ìš”ì²­í•©ë‹ˆë‹¤.
    
    # --- AI ì—°ë™ ì‹œë®¬ë ˆì´ì…˜ ---
    # ì‹¤ì œë¡œëŠ” ì´ ë¶€ë¶„ì— AI ëª¨ë¸ í˜¸ì¶œ ì½”ë“œê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤.
    # ì§€ê¸ˆì€ ì œê³µí•´ì£¼ì‹  ì˜ˆì‹œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    simulated_summaries = {
        "ë‰´ë§ê³ ": {
            "title": "'ë¶€í™œí•˜ê¸°' ê¸°ëŠ¥ UI/UX ë¶ˆë§Œ ì§€ì† ì¦ê°€",
            "quote": "ë¶€í™œí•˜ê¸° ë²„íŠ¼ìœ„ì¹˜ë¥¼ ë°”ê¿”ì£¼ë˜ì§€ í•´ì•¼ì§€ ê³„ì† ì‹¤ìˆ˜ë¡œ ëˆŒëŸ¬ì„œ êµ¬ìŠ¬ ì°¨ê°ë˜ë„¤ìš”"
        },
        "ì„¯ë‹¤": {
            "title": "ì¬í™” ë¶„ë¦¬ ì •ì±…ì— ëŒ€í•œ í˜¼ë€",
            "quote": "ì„¯ë‹¤ ë¨¸ë‹ˆê°€ í¬ì»¤ ì—ì„œ ì„¯ë‹¤ë¡œ ì˜®ê²¨ê°„ ë‹¤ìŒ í¬ì»¤ ë¨¸ë‹ˆê°€ ìë™ ë³µì‚¬ ëœ ë‹¤ê³  í•˜ì…¨ëŠ”ë° ìë™ ë³µì‚¬ ê¸°ëŠ¥ì´ ì–´ë””ì— ìˆì£ ~? ...ëˆì´ ë‹¤ë¥¸ë° ì™œ ëˆì´ ë‹¤ë¥´ì£ ~?"
        },
        "í¬ì»¤": {
            "title": "ì •ê¸°ê²°ì œ(í´ë˜ìŠ¤) í•´ì§€ ë¬¸ì˜ ì¦ê°€",
            "quote": "ì •ê¸°ê²°ì œ í•´ì§€ ë°©ë²•ì„ ì°¾ê¸° ì–´ë µë‹¤ëŠ” ë¶ˆë§Œê³¼ í™˜ë¶ˆ ìš”ì²­ì´ ì§€ì†ì ìœ¼ë¡œ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤."
        },
        "ë‰´ë² ê°€ìŠ¤": {
            "title": "ë¶ˆë²• ê´‘ê³  í•„í„°ë§ ê°•í™” ìš”ì²­",
            "quote": "ê·¸ë˜ë„ í”¼ë§ ëŒ€ê¸°ì—… ì•„ë‹˜? ê´‘ê³ ê°€ ë¶ˆë²•ê´‘ê³ ê°€ ë‚˜ì˜¤ë‚´ìš” ì˜¨ë¼ì¸ ì¹´ì§€ë…¸ ê°•ì›ëœë“œë¼ë‡¨..."
        },
        "ì‡¼ë‹¤ìš´í™€ë¤": {
            "title": "í‹°ì¼“ ì‚¬ìš©ì²˜ ë° ìŠ¤ì¼€ì¤„ ê°œì„  ìš”ì²­",
            "quote": "10ë§Œì§œë¦¬ ì¿ í°ì€ ì¶œì„ ë³´ìƒìœ¼ë¡œ ì™œ ì£¼ëŠ” ê±°ì—ìš”?ã…‹ã…‹ã…‹ ìƒˆë²½ 4ì‹œ 6ì‹œì—ë§Œ 10ë§Œ í† ë„ˆ ì—´ë©´ì„œã…‹ã…‹ã…‹ã…‹ã…‹"
        }
    }
    
    return simulated_summaries.get(_game_name, {"title": "ë¶„ì„ ì •ë³´ ì—†ìŒ", "quote": "-"})


def clean_text_for_wordcloud(text):
    if not isinstance(text, str): return ""
    text = re.sub(r'[^ã„±-ã…ã…-ã…£ê°€-í£\s]', '', text)
    return text.strip()

def classify_sentiment(text):
    if not isinstance(text, str): return "ì¤‘ë¦½"
    positive_keywords = ["ê°ì‚¬í•©ë‹ˆë‹¤", "ì¢‹ì•„ìš”", "ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤", "í•´ê²°", "ê³ ë§™ìŠµë‹ˆë‹¤"]
    negative_keywords = ["ì§œì¦", "ì˜¤ë¥˜", "í™˜ë¶ˆ", "ì•ˆë¼ìš”", "ì“°ë ˆê¸°", "ì¡°ì‘", "ë¶ˆë§Œ", "ë¬¸ì œ", "íŒ¨ëª°ë¦¼", "ì˜¤ë§"]
    text_lower = text.lower()
    if any(keyword in text_lower for keyword in negative_keywords): return "ë¶€ì •"
    if any(keyword in text_lower for keyword in positive_keywords): return "ê¸ì •"
    return "ì¤‘ë¦½"

def generate_wordcloud(text_data):
    """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•˜ê³  í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    cleaned_texts = [clean_text_for_wordcloud(text) for text in text_data]
    text = ' '.join(cleaned_texts)
    if not text.strip():
        st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í‚¤ì›Œë“œê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # [ìˆ˜ì •] í°íŠ¸ ê²½ë¡œë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì°¾ê¸° ìœ„í•œ ë¡œì§ ê°œì„ 
    font_path_relative = os.path.join('fonts', 'NanumGothic.ttf')
    font_path_windows = 'c:/Windows/Fonts/malgun.ttf'
    font_path = None

    if os.path.exists(font_path_relative):
        font_path = font_path_relative
    elif os.path.exists(font_path_windows):
        font_path = font_path_windows

    if font_path:
        korean_stopwords = ['ë¬¸ì˜', 'ê²Œì„', 'í”¼ë§', 'ê³ ê°', 'ë‚´ìš©', 'í™•ì¸', 'ë‹µë³€', 'ë¶€íƒ', 'ì²˜ë¦¬', 'ê´€ë ¨', 'ì•ˆë…•í•˜ì„¸ìš”']
        try:
            wordcloud = WordCloud(
                font_path=font_path, 
                width=400, # [ìˆ˜ì •] ë„ˆë¹„ ì ˆë°˜ìœ¼ë¡œ
                height=200, # [ìˆ˜ì •] ë†’ì´ ì ˆë°˜ìœ¼ë¡œ
                background_color='white', 
                stopwords=set(korean_stopwords)
            ).generate(text)
            
            # [ìˆ˜ì •] Figure í¬ê¸° ì¡°ì •
            fig, ax = plt.subplots(figsize=(4, 2))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)
        except Exception as e:
            st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        st.warning("ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±ì„ ìœ„í•œ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info("í”„ë¡œì íŠ¸ í´ë”ì— 'fonts' ë””ë ‰í† ë¦¬ë¥¼ ë§Œë“¤ê³  í•œê¸€ í°íŠ¸(.ttf)ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜, Windows í™˜ê²½ì¸ ê²½ìš° 'ë§‘ì€ ê³ ë”•' í°íŠ¸ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

def mask_phone_number(text):
    if not isinstance(text, str): return text
    masked_text = re.sub(r'(010[-.\s]?)\d{3,4}([-.\s]?)\d{4}', r'\1****\2****', text)
    return masked_text
    
def create_trend_chart(data, date_range, title):
    """[ê°œì„ ] ì¼ë³„ ì¶”ì´ ë¼ì¸ ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ì½”ë“œ ì¤‘ë³µ ì œê±°)"""
    start_date, end_date = pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1])
    all_days_in_range = pd.date_range(start=start_date, end=end_date, freq='D')
    range_df = pd.DataFrame(all_days_in_range, columns=['ë‚ ì§œ_dt'])
    
    daily_counts = data.groupby(data['ë‚ ì§œ_dt'].dt.date).size().reset_index(name="ê±´ìˆ˜")
    daily_counts['ë‚ ì§œ_dt'] = pd.to_datetime(daily_counts['ë‚ ì§œ_dt'])
    
    merged_data = pd.merge(range_df, daily_counts, on='ë‚ ì§œ_dt', how='left').fillna(0)
    merged_data['ê±´ìˆ˜'] = merged_data['ê±´ìˆ˜'].astype(int)

    fig = px.line(
        merged_data, x='ë‚ ì§œ_dt', y='ê±´ìˆ˜',
        title=f"<b>{title}</b>",
        labels={'ë‚ ì§œ_dt': 'ë‚ ì§œ', 'ê±´ìˆ˜': 'VOC ê±´ìˆ˜'}, 
        markers=True, text="ê±´ìˆ˜"
    )
    fig.update_traces(textposition="top center")
    fig.update_layout(xaxis_title="", yaxis_title="ê±´ìˆ˜", height=300)
    return fig

# [ë””ìì¸ ê°œì„ ] ë„ë„› ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜ ì¶”ê°€
def create_donut_chart(data, title):
    """ì£¼ìš” ì¹´í…Œê³ ë¦¬ TOP 5ì— ëŒ€í•œ ë„ë„› ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    category_counts = data['L2 íƒœê·¸'].value_counts()
    
    # ë°ì´í„°ê°€ 5ê°œ ì´ìƒì´ë©´ ìƒìœ„ 4ê°œ + 'ê¸°íƒ€'ë¡œ, 5ê°œ ë¯¸ë§Œì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if len(category_counts) > 5:
        top_4 = category_counts.nlargest(4)
        others_count = category_counts.iloc[4:].sum()
        chart_data = top_4._append(pd.Series([others_count], index=['ê¸°íƒ€']))
    else:
        chart_data = category_counts
        
    fig = go.Figure(data=[go.Pie(
        labels=chart_data.index, 
        values=chart_data.values, 
        hole=.6,
        textinfo='label+percent',
        insidetextorientation='radial'
    )])
    
    fig.update_layout(
        title_text=f"<b>{title}</b>",
        showlegend=False,
        height=300,
        margin=dict(l=20, r=20, t=60, b=20)
    )
    return fig

# [ë””ìì¸ ê°œì„ ] ë¡œì»¬ ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜
def get_image_as_base64(path):
    """ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì–´ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if os.path.exists(path):
        with open(path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode()
    return None

# --- 3. UI êµ¬ì„± ---
# [ë””ìì¸ ê°œì„ ] ë¡œê³ ì™€ í•¨ê»˜ ì œëª© í‘œì‹œ
logo_base64 = get_image_as_base64(LOGO_IMAGE)
if logo_base64:
    st.markdown(
        f"""
        <div style="display: flex; align-items: center; margin-bottom: 20px;">
            <img src="data:image/png;base64,{logo_base64}" width="200" style="margin-right: 15px;">
            <h1 style="margin: 0; font-size: 2.5rem;">ì›¹ë³´ë“œ VOC ëŒ€ì‹œë³´ë“œ</h1>
        </div>
        """,
        unsafe_allow_html=True,
    )
else:
    st.title("ğŸ“Š ì›¹ë³´ë“œ VOC ëŒ€ì‹œë³´ë“œ")


# [ë””ìì¸ ê°œì„ ] ì»¤ìŠ¤í…€ CSS ì¶”ê°€
st.markdown("""
<style>
    /* ë©”ì¸ í™”ë©´ ë°°ê²½ìƒ‰ */
    [data-testid="stAppViewContainer"] > .main {
        background-color: #f0f2f6;
    }

    /* ì‚¬ì´ë“œë°” ë°°ê²½ìƒ‰ */
    [data-testid="stSidebar"] {
        background-image: linear-gradient(#172a45, #0a192f);
    }

    /* [ë””ìì¸ ê°œì„ ] ì‚¬ì´ë“œë°” í…ìŠ¤íŠ¸ ìƒ‰ìƒ ë° êµµê¸° */
    [data-testid="stSidebar"] h1,
    [data-testid="stSidebar"] h3,
    [data-testid="stSidebar"] [data-testid="stDateInput"] label,
    [data-testid="stSidebar"] [data-testid="stCheckbox"] p {
        color: white !important;
        font-weight: bold !important;
    }

    /* ì „ì²´ ì»¨í…Œì´ë„ˆ(ì¹´ë“œ) ìŠ¤íƒ€ì¼ */
    [data-testid="stVerticalBlockBorderWrapper"] {
        background-color: #FFFFFF;
        border: 1px solid #E0E0E0;
        border-radius: 0.75rem;
        padding: 1.5rem;
        margin-bottom: 1rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.04);
    }
    
    /* í•µì‹¬ ì§€í‘œ(st.metric) ë‚´ë¶€ ìŠ¤íƒ€ì¼ - ë°°ê²½ìƒ‰ ì œê±°í•˜ì—¬ ì¹´ë“œì™€ í†µì¼ */
    [data-testid="stMetric"] {
        background-color: transparent;
        border: none;
        padding: 0;
        border-radius: 0;
        box-shadow: none;
    }

    /* [ë””ìì¸ ê°œì„ ] ê²Œì„ë³„ ë™í–¥ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .issue-card {
        background-color: #FFFFFF;
        border: 1px solid #E0E0E0;
        border-radius: 0.75rem;
        padding: 1rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.04);
        height: 100%;
    }
</style>
""", unsafe_allow_html=True)


st.markdown("---")

voc_data = load_data()

if voc_data.empty:
    st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Google Sheetsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    # --- ì‚¬ì´ë“œë°” UI ---
    with st.sidebar:
        st.title("ğŸ’» VOC ëŒ€ì‹œë³´ë“œ")
        
        st.markdown("### ğŸ•¹ï¸ ê²Œì„ ë° í”Œë«í¼ ì„ íƒ")
        game_filters = {
            "ë‰´ë§ê³ ": ["ë‰´ë§ê³  (ì „ì²´)", "ë‰´ë§ê³  MOB", "ë‰´ë§ê³  PC", "ë‰´ë§ê³  for kakao"],
            "ì„¯ë‹¤": ["ì„¯ë‹¤ (ì „ì²´)", "ì„¯ë‹¤ MOB", "ì„¯ë‹¤ PC", "ì„¯ë‹¤ for kakao"],
            "í¬ì»¤": ["í¬ì»¤ (ì „ì²´)", "í¬ì»¤ MOB", "í¬ì»¤ PC", "í¬ì»¤ for kakao"],
            "ì‡¼ë‹¤ìš´í™€ë¤": ["ì‡¼ë‹¤ìš´í™€ë¤ (ì „ì²´)", "ì‡¼ë‹¤ìš´í™€ë¤ MOB", "ì‡¼ë‹¤ìš´í™€ë¤ PC"],
            "ë‰´ë² ê°€ìŠ¤": ["ë‰´ë² ê°€ìŠ¤ (ì „ì²´)", "ë‰´ë² ê°€ìŠ¤ MOB", "ë‰´ë² ê°€ìŠ¤ PC"],
            "ê¸°íƒ€": ["ê¸°íƒ€"]
        }
        
        all_options_with_groups = [opt for sublist in game_filters.values() for opt in sublist]
        all_child_options = [opt for game, opts in game_filters.items() for opt in (opts[1:] if "(ì „ì²´)" in opts[0] else opts)]
        
        def master_checkbox_callback():
            is_all_selected = st.session_state.get('select_all', False)
            for option in all_options_with_groups:
                st.session_state[option] = is_all_selected

        def group_checkbox_callback(game_key):
            is_group_selected = st.session_state.get(f"{game_key} (ì „ì²´)", False)
            for option in game_filters[game_key][1:]:
                st.session_state[option] = is_group_selected
            update_master_checkbox()

        def child_checkbox_callback(game_key):
            if len(game_filters[game_key]) > 1:
                all_children_selected = all(st.session_state.get(opt, False) for opt in game_filters[game_key][1:])
                st.session_state[f"{game_key} (ì „ì²´)"] = all_children_selected
            update_master_checkbox()

        def update_master_checkbox():
            all_groups_selected = all(st.session_state.get(f"{game} (ì „ì²´)", False) for game, opts in game_filters.items() if len(opts) > 1 and "(ì „ì²´)" in opts[0])
            all_single_games_selected = all(st.session_state.get(opts[0], False) for game, opts in game_filters.items() if len(opts) == 1)
            st.session_state.select_all = all_groups_selected and all_single_games_selected
        
        if 'filters_initialized' not in st.session_state:
            st.session_state.filters_initialized = True
            st.session_state.select_all = True
            for option in all_options_with_groups:
                st.session_state[option] = True
        
        st.checkbox("ì „ì²´", key='select_all', on_change=master_checkbox_callback)

        for game, options in game_filters.items():
            with st.expander(game, expanded=True):
                if len(options) > 1 and "(ì „ì²´)" in options[0]:
                    st.checkbox(options[0], key=options[0], on_change=group_checkbox_callback, args=(game,))
                    for option in options[1:]:
                        st.checkbox(option, key=option, on_change=child_checkbox_callback, args=(game,))
                else:
                    st.checkbox(options[0], key=options[0], on_change=update_master_checkbox)

        selected_options = [option for option in all_child_options if st.session_state.get(option, False)]
        
    # --- [ìˆ˜ì •] í•„í„°ë§ ë¡œì§ ìˆœì„œ ë³€ê²½ ---
    # 1. ê²Œì„/í”Œë«í¼ í•„í„°ë§ì„ ë¨¼ì € ìˆ˜í–‰
    if not selected_options:
        game_filtered_data = pd.DataFrame()
    else:
        conditions = []
        # [ìˆ˜ì •] "for kakao" ì˜µì…˜ì„ ë” ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë„ë¡ ë¡œì§ ê°œì„ 
        for option in selected_options:
            if " for kakao" in option:
                game_name = option.replace(" for kakao", "")
                platform_name = "for kakao"
                conditions.append((voc_data['ê²Œì„'] == game_name) & (voc_data['í”Œë«í¼'] == platform_name))
            else:
                parts = option.rsplit(" ", 1)
                game_name = parts[0]
                platform_name = parts[1] if len(parts) > 1 else None

                if platform_name:
                    conditions.append((voc_data['ê²Œì„'] == game_name) & (voc_data['í”Œë«í¼'] == platform_name))
                else: # 'ê¸°íƒ€' ê°™ì€ ë‹¨ì¼ ì˜µì…˜
                    conditions.append(voc_data['ê²Œì„'] == game_name)

        if conditions:
            final_condition = pd.concat(conditions, axis=1).any(axis=1)
            game_filtered_data = voc_data[final_condition].copy()
        else:
            game_filtered_data = pd.DataFrame()
            
    # 2. ê²Œì„ í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‚ ì§œ ì„ íƒ UI ìƒì„±
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ğŸ“… ê¸°ê°„ ì„ íƒ")
        
        if game_filtered_data.empty:
            st.warning("ì„ íƒëœ ê²Œì„/í”Œë«í¼ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            # ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ì„ì‹œ ë‚ ì§œ ë²”ìœ„ ì„¤ì •
            date_range = (datetime.now().date() - timedelta(days=6), datetime.now().date())
        else:
            min_date_for_filter = game_filtered_data['ë‚ ì§œ_dt'].min().date()
            max_date_for_filter = game_filtered_data['ë‚ ì§œ_dt'].max().date()

            def set_date_range(days):
                # ì„ íƒëœ ë°ì´í„°ì˜ ìµœì‹  ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê¸°ê°„ ì„¤ì •
                start = max_date_for_filter - timedelta(days=days-1)
                # ì‹œì‘ì¼ì´ ë°ì´í„°ì˜ ìµœì´ˆ ë‚ ì§œë³´ë‹¤ ë¹ ë¥´ë©´ ìµœì´ˆ ë‚ ì§œë¡œ ì¡°ì •
                if start < min_date_for_filter:
                    start = min_date_for_filter
                st.session_state.date_range = (start, max_date_for_filter)

            col1, col2 = st.columns(2)
            with col1: st.button("ìµœê·¼ 7ì¼", on_click=set_date_range, args=(7,), use_container_width=True)
            with col2: st.button("ìµœê·¼ 30ì¼", on_click=set_date_range, args=(30,), use_container_width=True)

            # ì„¸ì…˜ ìƒíƒœì˜ ë‚ ì§œ ë²”ìœ„ ìœ íš¨ì„± ê²€ì‚¬ ë° ì´ˆê¸°í™”
            if 'date_range' not in st.session_state:
                set_date_range(7)
            else:
                # [ì˜¤ë¥˜ ìˆ˜ì •] st.session_state.date_rangeê°€ 2ê°œì˜ ê°’ì„ ê°€ì§€ëŠ”ì§€ í™•ì¸
                if isinstance(st.session_state.date_range, (list, tuple)) and len(st.session_state.date_range) == 2:
                    start_state, end_state = st.session_state.date_range
                    
                    start_state = max(start_state, min_date_for_filter)
                    end_state = min(end_state, max_date_for_filter)
                    
                    if start_state > end_state:
                        start_state = end_state

                    st.session_state.date_range = (start_state, end_state)
                else:
                    # session stateê°€ ê¹¨ì§„ ê²½ìš°, ì•ˆì „í•œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¬ì„¤ì •
                    set_date_range(7)

            date_range = st.date_input(
                "ì¡°íšŒ ê¸°ê°„:", 
                key='date_range', 
                min_value=min_date_for_filter, 
                max_value=max_date_for_filter
            )

    # 3. ìµœì¢…ì ìœ¼ë¡œ ë‚ ì§œ í•„í„°ë§ ìˆ˜í–‰
    if game_filtered_data.empty or len(date_range) != 2:
        filtered_data = pd.DataFrame()
    else:
        start_date = pd.to_datetime(date_range[0])
        end_date = pd.to_datetime(date_range[1])
        filtered_data = game_filtered_data[
            (game_filtered_data["ë‚ ì§œ_dt"] >= start_date) & 
            (game_filtered_data["ë‚ ì§œ_dt"] <= end_date)
        ].copy()


    # --- ë©”ì¸ ëŒ€ì‹œë³´ë“œ UI ---
    if filtered_data.empty:
        st.warning(f"ì„ íƒí•˜ì‹  ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” VOC ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # [ë””ìì¸ ê°œì„ ] ì»¨í…Œì´ë„ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¹ì…˜ êµ¬ë¶„
        with st.container(border=True):
            st.header("ğŸš€ í•µì‹¬ ì§€í‘œ ìš”ì•½")
            st.markdown(f"**ê¸°ê°„: {date_range[0].strftime('%Y-%m-%d')} ~ {date_range[1].strftime('%Y-%m-%d')}**")
            
            # ì´ì „ ê¸°ê°„ ëŒ€ë¹„ ì¦ê°ë¥  ê³„ì‚° ë¡œì§
            current_count = len(filtered_data)
            period_days = (date_range[1] - date_range[0]).days + 1
            prev_start_date = date_range[0] - timedelta(days=period_days)
            prev_end_date = date_range[1] - timedelta(days=period_days)
            prev_period_data = game_filtered_data[
                (game_filtered_data["ë‚ ì§œ_dt"] >= pd.to_datetime(prev_start_date)) & 
                (game_filtered_data["ë‚ ì§œ_dt"] <= pd.to_datetime(prev_end_date))
            ]
            prev_count = len(prev_period_data)
            delta = current_count - prev_count
            
            col1, col2 = st.columns([1, 2])
            with col1:
                delta_text = f"{delta} ê±´ (ì´ì „ ë™ì¼ ê¸°ê°„ ëŒ€ë¹„)"
                st.metric("ì´ VOC ê±´ìˆ˜", f"{current_count} ê±´", delta_text, help=f"ì´ì „ ê¸°ê°„: {prev_start_date.strftime('%Y-%m-%d')}~{prev_end_date.strftime('%Y-%m-%d')}")
            
            with col2:
                fig_donut = create_donut_chart(filtered_data, "ì£¼ìš” ì¹´í…Œê³ ë¦¬ TOP 5")
                st.plotly_chart(fig_donut, use_container_width=True)
            
            st.markdown("---")
            st.subheader("ğŸ‘ª ê²Œì„ë³„ ì£¼ìš” ë™í–¥ (AI ìš”ì•½)")
            st.info("ì•„ë˜ ë‚´ìš©ì€ ì„ íƒëœ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ë™ì ìœ¼ë¡œ ìƒì„±í•œ ìš”ì•½ì…ë‹ˆë‹¤. (í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜)")

            # ê²Œì„ë³„ ì£¼ìš” ë™í–¥ ë°ì´í„° (AI ì—°ë™ ì‹œë®¬ë ˆì´ì…˜)
            game_list_for_summary = ["ë‰´ë§ê³ ", "ì„¯ë‹¤", "í¬ì»¤", "ë‰´ë² ê°€ìŠ¤", "ì‡¼ë‹¤ìš´í™€ë¤"]
            game_icons = {"ë‰´ë§ê³ ": "ğŸ´", "ì„¯ë‹¤": "ğŸ´", "í¬ì»¤": "â™£ï¸", "ë‰´ë² ê°€ìŠ¤": "ğŸ°", "ì‡¼ë‹¤ìš´í™€ë¤": "â™ ï¸"}
            
            issue_cols = st.columns(5)
            for i, game_name in enumerate(game_list_for_summary):
                with issue_cols[i]:
                    game_data = filtered_data[filtered_data['ê²Œì„'] == game_name]
                    summary = get_game_issue_summary(game_name, game_data)
                    
                    # [ë””ìì¸ ê°œì„ ] ìƒˆë¡œìš´ ì¹´ë“œ ë ˆì´ì•„ì›ƒ ì ìš©
                    st.markdown(
                        f"""
                        <div class="issue-card">
                            <h5>{game_icons.get(game_name, "ğŸƒ")} {game_name}</h5>
                            <p><strong>{summary['title']}</strong></p>
                            <blockquote style="font-size: 0.9rem; color: #6c757d;">"{summary['quote']}"</blockquote>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )


        st.markdown("---")
        
        tab_main, tab_search = st.tabs(["### ğŸ“Š ì¹´í…Œê³ ë¦¬ ë¶„ì„", "### ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰"])
        
        with tab_main:
            # [ë””ìì¸ ê°œì„ ] ì°¨íŠ¸ë¥¼ ê°€ë¡œë¡œ ë°°ì¹˜í•˜ê¸° ìœ„í•´ ì»¬ëŸ¼ ì‚¬ìš©
            col1, col2 = st.columns(2)
            with col1:
                with st.container(border=True):
                    fig_daily_trend = create_trend_chart(filtered_data, date_range, f"ì¼ìë³„ VOC ë°œìƒ ì¶”ì´")
                    st.plotly_chart(fig_daily_trend, use_container_width=True)
            
            with col2:
                with st.container(border=True):
                    l2_counts = filtered_data['L2 íƒœê·¸'].value_counts().nlargest(10).sort_values(ascending=True)
                    fig_l2 = px.bar(
                        l2_counts, x=l2_counts.values, y=l2_counts.index, orientation='h', 
                        title="<b>íƒœê·¸ë³„ í˜„í™© TOP 10</b>", labels={'x': 'ê±´ìˆ˜', 'y': 'íƒœê·¸'}, text_auto=True
                    )
                    fig_l2.update_layout(height=300)
                    st.plotly_chart(fig_l2, use_container_width=True)
            
            st.write("") # ê°„ê²© ì¡°ì ˆ

            with st.container(border=True):
                st.header("ğŸ“‘ VOC ì›ë³¸ ë°ì´í„°")
                col1, col2 = st.columns([3, 1])
                with col1:
                    top5_categories = filtered_data['L2 íƒœê·¸'].value_counts().nlargest(5)
                    all_categories = sorted(filtered_data['L2 íƒœê·¸'].unique())
                    selected_categories = st.multiselect("í™•ì¸í•˜ê³  ì‹¶ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:", options=all_categories, default=top5_categories.index.tolist())
                
                if selected_categories:
                    display_data = filtered_data[filtered_data['L2 íƒœê·¸'].isin(selected_categories)].copy()
                    with col2:
                        st.text(" ") # ë²„íŠ¼ ìœ„ì¹˜ ì¡°ì •ì„ ìœ„í•œ ë¹ˆ ê³µê°„
                        st.download_button(
                            label="ğŸ“¥ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
                            data=display_data.to_csv(index=False).encode('utf-8-sig'),
                            file_name=f"voc_category_data_{datetime.now().strftime('%Y%m%d')}.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                    display_data['ë¬¸ì˜ë‚´ìš©_ìš”ì•½'] = display_data['ë¬¸ì˜ë‚´ìš©_ìš”ì•½'].apply(mask_phone_number)
                    display_df = display_data.rename(columns={'í”Œë«í¼': 'êµ¬ë¶„', 'ë¬¸ì˜ë‚´ìš©_ìš”ì•½': 'ë¬¸ì˜ ë‚´ìš©'})
                    st.dataframe(display_df[["êµ¬ë¶„", "ë‚ ì§œ", "ê²Œì„", "L2 íƒœê·¸", "ìƒë‹´ì œëª©", "ë¬¸ì˜ ë‚´ìš©", "GSN(USN)", "ê¸°ê¸°ì •ë³´"]], use_container_width=True, height=500)

        with tab_search:
            st.header("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰")
            
            # [ìˆ˜ì •] ê²€ìƒ‰ì°½ê³¼ ë²„íŠ¼ì„ ê°€ë¡œë¡œ ë°°ì¹˜í•˜ê³ , ë²„íŠ¼ í´ë¦­ ë° ì—”í„° ëª¨ë‘ ì§€ì›
            col1, col2 = st.columns([5, 1])
            with col1:
                search_keyword = st.text_input(
                    "ê²€ìƒ‰í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", 
                    placeholder="ì˜ˆ: í™˜ë¶ˆ, íŠ•ê¹€, ì—…ë°ì´íŠ¸..."
                )
            with col2:
                # text_inputì˜ ë ˆì´ë¸”ê³¼ ë†’ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•œ ë¹ˆ ê³µê°„
                st.write(" ")
                st.button("ê²€ìƒ‰", use_container_width=True)

            if search_keyword:
                search_results = filtered_data[filtered_data["ìƒë‹´ì œëª©"].str.contains(search_keyword, na=False, case=False) | filtered_data["ê²€ìƒ‰ìš©_ë¬¸ì˜ë‚´ìš©"].str.contains(search_keyword, na=False, case=False)].copy()
                if not search_results.empty:
                    st.success(f"âœ… \"{search_keyword}\" í‚¤ì›Œë“œê°€ í¬í•¨ëœ VOC: **{len(search_results)}**ê±´")
                    
                    # [ìˆ˜ì •] 'ê°ì„±' ì»¬ëŸ¼ì„ ì´ ìœ„ì¹˜ì—ì„œ ìƒì„±
                    search_results['ê°ì„±'] = search_results['ë¬¸ì˜ë‚´ìš©'].apply(classify_sentiment)

                    with st.container(border=True):
                        st.header(f"'{search_keyword}' í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ì´")
                        fig_search_trend = create_trend_chart(search_results, date_range, f"'{search_keyword}' í‚¤ì›Œë“œ ì¼ìë³„ ë°œìƒ ì¶”ì´")
                        st.plotly_chart(fig_search_trend, use_container_width=True)

                    with st.container(border=True):
                        st.header("ê´€ë ¨ VOC ëª©ë¡")
                        st.download_button(
                            label="ğŸ“¥ ê²€ìƒ‰ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                            data=search_results.to_csv(index=False).encode('utf-8-sig'),
                            file_name=f"voc_search_{search_keyword}_{datetime.now().strftime('%Y%m%d')}.csv",
                            mime="text/csv"
                        )
                        search_results['ë¬¸ì˜ë‚´ìš©_ìš”ì•½'] = search_results['ë¬¸ì˜ë‚´ìš©_ìš”ì•½'].apply(mask_phone_number)
                        display_search_df = search_results.rename(columns={'í”Œë«í¼': 'êµ¬ë¶„', 'ë¬¸ì˜ë‚´ìš©_ìš”ì•½': 'ë¬¸ì˜ ë‚´ìš©'})
                        st.dataframe(display_search_df[["êµ¬ë¶„", "ë‚ ì§œ", "ê²Œì„", "L2 íƒœê·¸", "ìƒë‹´ì œëª©", "ë¬¸ì˜ ë‚´ìš©", "GSN(USN)", "ê¸°ê¸°ì •ë³´", "ê°ì„±"]], use_container_width=True, height=400)

                    st.write("") # ê°„ê²© ì¡°ì ˆ
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        with st.container(border=True):
                            st.header("ê°ì„± ë¶„ì„ ê²°ê³¼")
                            sentiment_counts = search_results['ê°ì„±'].value_counts()
                            sentiment_cols = st.columns(3)
                            sentiment_cols[0].metric("ê¸ì • ğŸ˜Š", f"{sentiment_counts.get('ê¸ì •', 0)} ê±´")
                            sentiment_cols[1].metric("ë¶€ì • ğŸ˜ ", f"{sentiment_counts.get('ë¶€ì •', 0)} ê±´")
                            sentiment_cols[2].metric("ì¤‘ë¦½ ğŸ˜", f"{sentiment_counts.get('ì¤‘ë¦½', 0)} ê±´")
                    with col2:
                        with st.container(border=True):
                            st.header("ì—°ê´€ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
                            generate_wordcloud(search_results["ë¬¸ì˜ë‚´ìš©"])

                else:
                    st.warning(f"âš ï¸ \"{search_keyword}\" í‚¤ì›Œë“œê°€ í¬í•¨ëœ VOCê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")
    logo_base64 = get_image_as_base64(LOGO_IMAGE)
    if logo_base64:
        footer_html = f"""
        <div style="text-align: center; padding-top: 20px; padding-bottom: 20px;">
            <img src="data:image/png;base64,{logo_base64}" width="100">
            <p style="font-size: 0.8rem; color: #6c757d; margin-top: 10px;">Â© NEOWIZ Corp. All Rights Reserved.</p>
        </div>
        """
        st.markdown(footer_html, unsafe_allow_html=True)

