# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import re

# --- 1. ê¸°ë³¸ ì„¤ì • ---
# Google Sheets ë° í˜ì´ì§€ ì„¤ì •
SPREADSHEET_ID = "1rgR21yUBtKSJKE4KYdBvoZzDU-0jZ_wLb6Tqc_zS7RM"
SERVICE_ACCOUNT_FILE = "service_account.json"

st.set_page_config(page_title="í”¼ë§ ì›¹ë³´ë“œ VOC ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")

# L2 íƒœê·¸ë¥¼ L1 ëŒ€ë¶„ë¥˜ë¡œ ë§¤í•‘í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬
L2_TO_L1_MAPPING = {
    'ë¡œê·¸ì¸/ì¸ì¦': 'ê³„ì •', 'ì •ë³´ ê´€ë¦¬': 'ê³„ì •',
    'ê¸°ìˆ  ì˜¤ë¥˜': 'ì‹œìŠ¤í…œ/í™˜ê²½',
    'ê²°ì œ ì˜¤ë¥˜/ë¯¸ì§€ê¸‰': 'ì¬í™”/ê²°ì œ', 'í™˜ë¶ˆ/ì²­ì•½ì² íšŒ': 'ì¬í™”/ê²°ì œ', 'ì¬í™” ì†Œì‹¤/ì˜¤ë¥˜': 'ì¬í™”/ê²°ì œ',
    'í´ë˜ìŠ¤/êµ¬ë… ìƒí’ˆ': 'ì¬í™”/ê²°ì œ', 'ì¬í™” ì •ì±…/í•œë„': 'ì¬í™”/ê²°ì œ',
    'ë°¸ëŸ°ìŠ¤/ë¶ˆë§Œ (íŒ¨ëª°ë¦¼)': 'ê²Œì„ í”Œë ˆì´', 'ì½˜í…ì¸  ì˜¤ë¥˜/ë¬¸ì˜': 'ê²Œì„ í”Œë ˆì´', 'í† ë„ˆë¨¼íŠ¸/ëŒ€íšŒ': 'ê²Œì„ í”Œë ˆì´',
    'ì ë ¹ì „/ê±°ì ì „': 'ê²Œì„ í”Œë ˆì´', 'ë­í‚¹í˜ìŠ¤íƒ€': 'ê²Œì„ í”Œë ˆì´', 'ì—°ìŠ¹ì±Œë¦°ì§€': 'ê²Œì„ í”Œë ˆì´', 'íŒ¨ë°€ë¦¬ê²Œì„': 'ê²Œì„ í”Œë ˆì´',
    'ê´‘ê³ /ë¬´ë£Œì¶©ì „ì†Œ': 'ì´ë²¤íŠ¸/í˜œíƒ', 'ì´ë²¤íŠ¸': 'ì´ë²¤íŠ¸/í˜œíƒ',
    'ë¹„ë§¤ë„ˆ/ìš•ì„¤ ì‹ ê³ ': 'ë¶ˆëŸ‰ ì´ìš©ì', 'ì œì¬ ë¬¸ì˜': 'ë¶ˆëŸ‰ ì´ìš©ì',
    'ì½˜í…ì¸ /ì‹œìŠ¤í…œ ê±´ì˜': 'ì •ì±…/ê±´ì˜ (VOC)', 'ìš´ì˜/ì •ì±… ê±´ì˜': 'ì •ì±…/ê±´ì˜ (VOC)',
    'ë‹¨ìˆœ ë¬¸ì˜/ë¯¸ë¶„ë¥˜': 'ê¸°íƒ€'
}

# --- 2. ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ ---

def classify_game(category):
    """'MOBì„¯ë‹¤', 'PCë‰´ë§ê³ ' ë“± ë‹¤ì–‘í•œ í˜•ì‹ì„ í‘œì¤€ ê²Œì„ ì´ë¦„ìœ¼ë¡œ í†µí•©í•˜ëŠ” í•¨ìˆ˜"""
    if pd.isna(category):
        return "ê¸°íƒ€"
    
    category = str(category).lower()
    
    if "ë‰´ë§ê³ " in category or "newmatgo" in category: return "ë‰´ë§ê³ "
    if "ì„¯ë‹¤" in category or "sutda" in category: return "ì„¯ë‹¤"
    if "í¬ì»¤" in category or "poker" in category: return "í¬ì»¤"
    if "ì‡¼ë‹¤ìš´í™€ë¤" in category or "showdown" in category: return "ì‡¼ë‹¤ìš´í™€ë¤"
    if "ë‰´ë² ê°€ìŠ¤" in category or "newvegas" in category: return "ë‰´ë² ê°€ìŠ¤"
    return "ê¸°íƒ€"

@st.cache_data(ttl=600) # 10ë¶„ë§ˆë‹¤ ë°ì´í„° ìƒˆë¡œê³ ì¹¨
def load_data():
    """Google Sheetsì—ì„œ ëª¨ë“  VOC ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    try:
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds = ServiceAccountCredentials.from_json_keyfile_name(SERVICE_ACCOUNT_FILE, scope)
        gc = gspread.authorize(creds)
        
        spreadsheet = gc.open_by_key(SPREADSHEET_ID)
        worksheets = spreadsheet.worksheets()
        all_data = []
        
        for worksheet in worksheets:
            if worksheet.title.lower() not in ["sheet1", "template", "mapping"]:
                try:
                    data = worksheet.get_all_records()
                    if data:
                        for row in data: row["ë‚ ì§œ"] = worksheet.title
                        all_data.extend(data)
                except Exception: continue
        
        if not all_data: return pd.DataFrame()
        df = pd.DataFrame(all_data)
        
        required_cols = ["ì ‘ìˆ˜ ì¹´í…Œê³ ë¦¬", "ìƒë‹´ì œëª©", "ë¬¸ì˜ë‚´ìš©", "taglist"]
        if not all(col in df.columns for col in required_cols):
            st.error(f"í•„ìˆ˜ ì»¬ëŸ¼({required_cols})ì´ Google Sheetsì— ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        df.rename(columns={'taglist': 'L2 íƒœê·¸'}, inplace=True)
        df["ê²Œì„"] = df["ì ‘ìˆ˜ ì¹´í…Œê³ ë¦¬"].apply(classify_game)
        df["ë‚ ì§œ_dt"] = pd.to_datetime(df["ë‚ ì§œ"], format='%y%m%d', errors='coerce')
        df = df.dropna(subset=["ë‚ ì§œ_dt"])
        df['L1 íƒœê·¸'] = df['L2 íƒœê·¸'].map(L2_TO_L1_MAPPING).fillna('ê¸°íƒ€')
        df['ì£¼ì°¨'] = df['ë‚ ì§œ_dt'].dt.to_period('W-MON')
        return df

    except Exception as e:
        st.error(f"Google Sheets ì—°ê²° ë˜ëŠ” ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

def clean_text_for_wordcloud(text):
    if not isinstance(text, str): return ""
    text = re.sub(r'íšŒì›ë²ˆí˜¸\s*:\s*\d+|íšŒì›ë¶„ë¥˜\s*:\s*\w+|ë£¨íŒ…ì—¬ë¶€\s*:\s*\w+|OS version\s*:.*|app version\s*:.*|íœ´ëŒ€í°ê¸°ê¸°ì •ë³´\s*:.*', '', text)
    text = re.sub(r'[^ã„±-ã…ã…-ã…£ê°€-í£\s]', '', text)
    return text.strip()

def classify_sentiment(text):
    if not isinstance(text, str): return "ì¤‘ë¦½"
    positive_keywords = ["ê°ì‚¬í•©ë‹ˆë‹¤", "ì¢‹ì•„ìš”", "ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤", "í•´ê²°", "ê³ ë§™ìŠµë‹ˆë‹¤"]
    negative_keywords = ["ì§œì¦", "ì˜¤ë¥˜", "í™˜ë¶ˆ", "ì•ˆë¼ìš”", "ì“°ë ˆê¸°", "ì¡°ì‘", "ë¶ˆë§Œ", "ë¬¸ì œ", "íŒ¨ëª°ë¦¼", "ì˜¤ë§"]
    text_lower = text.lower()
    if any(keyword in text_lower for keyword in negative_keywords): return "ë¶€ì •"
    if any(keyword in text_lower for keyword in positive_keywords): return "ê¸ì •"
    return "ì¤‘ë¦½"

def generate_wordcloud(text_data):
    cleaned_texts = [clean_text_for_wordcloud(text) for text in text_data]
    text = ' '.join(cleaned_texts)
    
    if not text.strip():
        st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í‚¤ì›Œë“œê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    font_path = 'c:/Windows/Fonts/malgun.ttf'
    korean_stopwords = ['ë¬¸ì˜', 'ê²Œì„', 'í”¼ë§', 'ê³ ê°', 'ë‚´ìš©', 'í™•ì¸', 'ë‹µë³€', 'ë¶€íƒ', 'ì²˜ë¦¬', 'ê´€ë ¨', 'ì•ˆë…•í•˜ì„¸ìš”']
    
    try:
        wordcloud = WordCloud(
            font_path=font_path, width=800, height=400, background_color='white',
            stopwords=set(korean_stopwords)
        ).generate(text)
        
        fig, ax = plt.subplots(figsize=(5, 2.5))
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis('off')
        st.pyplot(fig)
    except FileNotFoundError:
        st.warning("ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±ì„ ìœ„í•œ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (malgun.ttf)")
    except Exception as e:
        st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- 3. UI êµ¬ì„± ---
st.title("ğŸ“Š í”¼ë§ ì›¹ë³´ë“œ VOC ëŒ€ì‹œë³´ë“œ")
st.markdown("---")

voc_data = load_data()

if voc_data.empty:
    st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Google Sheetsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    with st.sidebar:
        st.title("ğŸ® VOC ëŒ€ì‹œë³´ë“œ í•„í„°")
        game_list = ["ì „ì²´", "ë‰´ë§ê³ ", "ì„¯ë‹¤", "í¬ì»¤", "ì‡¼ë‹¤ìš´í™€ë¤", "ë‰´ë² ê°€ìŠ¤"]
        selected_game = st.selectbox("ê²Œì„ì„ ì„ íƒí•˜ì„¸ìš”:", game_list)
        
        st.markdown("---")
        st.markdown("### ğŸ“… ê¸°ê°„ ì„ íƒ")
        def set_date_range(days):
            max_date = voc_data['ë‚ ì§œ_dt'].max().date()
            st.session_state.date_range = (max_date - timedelta(days=days-1), max_date)
        col1, col2 = st.columns(2)
        with col1: st.button("ìµœê·¼ 7ì¼", on_click=set_date_range, args=(7,), use_container_width=True)
        with col2: st.button("ìµœê·¼ 30ì¼", on_click=set_date_range, args=(30,), use_container_width=True)
        if 'date_range' not in st.session_state: set_date_range(7)
        date_range = st.date_input("ì¡°íšŒ ê¸°ê°„:", key='date_range', min_value=voc_data['ë‚ ì§œ_dt'].min().date(), max_value=voc_data['ë‚ ì§œ_dt'].max().date())

    if selected_game != "ì „ì²´":
        filtered_data = voc_data[voc_data["ê²Œì„"] == selected_game].copy()
    else:
        filtered_data = voc_data.copy()

    if len(date_range) == 2:
        start_date = pd.to_datetime(date_range[0])
        end_date = pd.to_datetime(date_range[1])
        filtered_data = filtered_data[(filtered_data["ë‚ ì§œ_dt"] >= start_date) & (filtered_data["ë‚ ì§œ_dt"] <= end_date)]

    if filtered_data.empty:
        st.warning(f"ì„ íƒí•˜ì‹  ê¸°ê°„ê³¼ ê²Œì„ì— í•´ë‹¹í•˜ëŠ” VOC ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.header("ğŸš€ í•µì‹¬ ì§€í‘œ ìš”ì•½")
        current_period_start = pd.to_datetime(date_range[0])
        current_period_end = pd.to_datetime(date_range[1])
        period_days = (current_period_end - current_period_start).days + 1
        previous_period_start = current_period_start - timedelta(days=period_days)
        previous_period_end = current_period_start - timedelta(days=1)
        previous_data_base = voc_data[(voc_data["ë‚ ì§œ_dt"] >= previous_period_start) & (voc_data["ë‚ ì§œ_dt"] <= previous_period_end)]
        if selected_game != "ì „ì²´":
            previous_data = previous_data_base[previous_data_base["ê²Œì„"] == selected_game]
        else:
            previous_data = previous_data_base
        current_count = len(filtered_data)
        previous_count = len(previous_data)
        change_percent = ((current_count - previous_count) / previous_count * 100) if previous_count > 0 else 0
        top3_categories = filtered_data['L2 íƒœê·¸'].value_counts().nlargest(3)

        col1, col2, col3 = st.columns(3)
        col1.metric("ì´ VOC ê±´ìˆ˜", f"{current_count} ê±´")
        col2.metric("ì´ì „ ê¸°ê°„ ëŒ€ë¹„", f"{change_percent:.1f} %", f"{current_count - previous_count} ê±´")
        with col3:
            st.markdown("**ì£¼ìš” ì¹´í…Œê³ ë¦¬ TOP 3**")
            for i, (cat, count) in enumerate(top3_categories.items()):
                st.markdown(f"**{i+1}.** {cat} ({count}ê±´)")

        st.markdown("---")
        
        st.header("ğŸ“… ì›”ë³„ VOC ë°œìƒ ì¶”ì´")
        today = datetime.now()
        first_day_of_month = today.replace(day=1)
        # Get the number of days in the current month
        next_month = first_day_of_month.replace(month=first_day_of_month.month % 12 + 1, year=first_day_of_month.year + first_day_of_month.month // 12)
        last_day_of_month = next_month - timedelta(days=1)
        
        all_days_in_month = pd.date_range(start=first_day_of_month.date(), end=last_day_of_month.date(), freq='D')
        month_df = pd.DataFrame(all_days_in_month, columns=['ë‚ ì§œ_dt'])
        daily_counts = filtered_data.groupby(filtered_data['ë‚ ì§œ_dt'].dt.date).size().reset_index(name="ê±´ìˆ˜")
        daily_counts['ë‚ ì§œ_dt'] = pd.to_datetime(daily_counts['ë‚ ì§œ_dt'])
        merged_daily_data = pd.merge(month_df, daily_counts, on='ë‚ ì§œ_dt', how='left').fillna(0)
        
        fig_daily_trend = px.line(
            merged_daily_data, x='ë‚ ì§œ_dt', y='ê±´ìˆ˜',
            title=f"<b>{today.strftime('%Yë…„ %mì›”')} ì¼ìë³„ VOC ì¶”ì´</b>",
            labels={'ë‚ ì§œ_dt': 'ë‚ ì§œ', 'ê±´ìˆ˜': 'VOC ê±´ìˆ˜'}, markers=True
        )
        fig_daily_trend.update_layout(xaxis_title="", yaxis_title="ê±´ìˆ˜")
        st.plotly_chart(fig_daily_trend, use_container_width=True)
        st.markdown("---")

        tab_main, tab_search = st.tabs(["ğŸ“Š ì¹´í…Œê³ ë¦¬ ë¶„ì„", "ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰"])
        with tab_main:
            st.header("ğŸ“Œ VOC ì¹´í…Œê³ ë¦¬ë³„ í˜„í™©")
            l2_counts = filtered_data['L2 íƒœê·¸'].value_counts().nlargest(10).sort_values(ascending=True)
            fig_l2 = px.bar(l2_counts, x=l2_counts.values, y=l2_counts.index, orientation='h', title="<b>íƒœê·¸ë³„ í˜„í™© TOP 10</b>", labels={'x': 'ê±´ìˆ˜', 'y': 'íƒœê·¸'})
            st.plotly_chart(fig_l2, use_container_width=True)
            st.subheader("ğŸ“‘ VOC ì›ë³¸ ë°ì´í„°")
            all_categories = sorted(filtered_data['L2 íƒœê·¸'].unique())
            selected_categories = st.multiselect("í™•ì¸í•˜ê³  ì‹¶ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:", options=all_categories, default=top3_categories.index.tolist())
            if selected_categories:
                display_data = filtered_data[filtered_data['L2 íƒœê·¸'].isin(selected_categories)]
                st.dataframe(display_data[["ë‚ ì§œ", "ê²Œì„", "L2 íƒœê·¸", "ìƒë‹´ì œëª©", "ë¬¸ì˜ë‚´ìš©"]], use_container_width=True, height=500)

        with tab_search:
            st.header("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰")
            search_keyword = st.text_input("ë¶„ì„í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: í™˜ë¶ˆ, íŠ•ê¹€, ì—…ë°ì´íŠ¸...")
            if search_keyword:
                search_results = filtered_data[filtered_data["ìƒë‹´ì œëª©"].str.contains(search_keyword, na=False, case=False) | filtered_data["ë¬¸ì˜ë‚´ìš©"].str.contains(search_keyword, na=False, case=False)].copy()
                if not search_results.empty:
                    st.success(f"âœ… \"{search_keyword}\" í‚¤ì›Œë“œê°€ í¬í•¨ëœ VOC: **{len(search_results)}**ê±´")
                    search_results['ê°ì„±'] = search_results['ë¬¸ì˜ë‚´ìš©'].apply(classify_sentiment)
                    sentiment_counts = search_results['ê°ì„±'].value_counts()
                    st.subheader("ê°ì„± ë¶„ì„ ê²°ê³¼")
                    sentiment_cols = st.columns(3)
                    sentiment_cols[0].metric("ê¸ì • ğŸ˜Š", f"{sentiment_counts.get('ê¸ì •', 0)} ê±´")
                    sentiment_cols[1].metric("ë¶€ì • ğŸ˜ ", f"{sentiment_counts.get('ë¶€ì •', 0)} ê±´")
                    sentiment_cols[2].metric("ì¤‘ë¦½ ğŸ˜", f"{sentiment_counts.get('ì¤‘ë¦½', 0)} ê±´")
                    
                    st.subheader("ê´€ë ¨ VOC ëª©ë¡")
                    st.dataframe(search_results[["ë‚ ì§œ", "L2 íƒœê·¸", "ìƒë‹´ì œëª©", "ë¬¸ì˜ë‚´ìš©", "ê°ì„±"]], use_container_width=True, height=400)
                    
                    st.subheader("ì—°ê´€ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
                    generate_wordcloud(search_results["ë¬¸ì˜ë‚´ìš©"])
                else:
                    st.warning(f"âš ï¸ \"{search_keyword}\" í‚¤ì›Œë“œê°€ í¬í•¨ëœ VOCê°€ ì—†ìŠµë‹ˆë‹¤.")

