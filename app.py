# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import gspread
from google.oauth2 import service_account # [ìˆ˜ì •] ìµœì‹  ì¸ì¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë³€ê²½
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import re
import os
import base64

# --- 1. ê¸°ë³¸ ì„¤ì • ---
LOGO_IMAGE = "images/pmang_logo.png"
st.set_page_config(page_title="ì›¹ë³´ë“œ VOC ëŒ€ì‹œë³´ë“œ", page_icon=LOGO_IMAGE, layout="wide")

L2_TO_L1_MAPPING = {
    'ë¡œê·¸ì¸/ì¸ì¦': 'ê³„ì •', 'ì •ë³´ ê´€ë¦¬': 'ê³„ì •', 'ê¸°ìˆ  ì˜¤ë¥˜': 'ì‹œìŠ¤í…œ/í™˜ê²½',
    'ê²°ì œ ì˜¤ë¥˜/ë¯¸ì§€ê¸‰': 'ì¬í™”/ê²°ì œ', 'í™˜ë¶ˆ/ì²­ì•½ì² íšŒ': 'ì¬í™”/ê²°ì œ', 'ì¬í™” ì†Œì‹¤/ì˜¤ë¥˜': 'ì¬í™”/ê²°ì œ',
    'í´ë˜ìŠ¤/êµ¬ë… ìƒí’ˆ': 'ì¬í™”/ê²°ì œ', 'ì¬í™” ì •ì±…/í•œë„': 'ì¬í™”/ê²°ì œ', 'ë°¸ëŸ°ìŠ¤/ë¶ˆë§Œ (íŒ¨ëª°ë¦¼)': 'ê²Œì„ í”Œë ˆì´',
    'ì½˜í…ì¸  ì˜¤ë¥˜/ë¬¸ì˜': 'ê²Œì„ í”Œë ˆì´', 'í† ë„ˆë¨¼íŠ¸/ëŒ€íšŒ': 'ê²Œì„ í”Œë ˆì´', 'ì ë ¹ì „/ê±°ì ì „': 'ê²Œì„ í”Œë ˆì´',
    'ë­í‚¹í˜ìŠ¤íƒ€': 'ê²Œì„ í”Œë ˆì´', 'ì—°ìŠ¹ì±Œë¦°ì§€': 'ê²Œì„ í”Œë ˆì´', 'íŒ¨ë°€ë¦¬ê²Œì„': 'ê²Œì„ í”Œë ˆì´',
    'ê´‘ê³ /ë¬´ë£Œì¶©ì „ì†Œ': 'ì´ë²¤íŠ¸/í˜œíƒ', 'ì´ë²¤íŠ¸': 'ì´ë²¤íŠ¸/í˜œíƒ', 'ë¹„ë§¤ë„ˆ/ìš•ì„¤ ì‹ ê³ ': 'ë¶ˆëŸ‰ ì´ìš©ì',
    'ì œì¬ ë¬¸ì˜': 'ë¶ˆëŸ‰ ì´ìš©ì', 'ì½˜í…ì¸ /ì‹œìŠ¤í…œ ê±´ì˜': 'ì •ì±…/ê±´ì˜ (VOC)', 'ìš´ì˜/ì •ì±… ê±´ì˜': 'ì •ì±…/ê±´ì˜ (VOC)',
    'ë‹¨ìˆœ ë¬¸ì˜/ë¯¸ë¶„ë¥˜': 'ê¸°íƒ€'
}

# --- 2. ë°ì´í„° ì²˜ë¦¬ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def classify_game(category):
    if pd.isna(category): return "ê¸°íƒ€"
    processed_category = re.sub(r'[^a-z0-9ã„±-ã…ã…-ã…£ê°€-í£]', '', str(category).lower())
    if "ì‡¼ë‹¤ìš´í™€ë¤" in processed_category or "showdown" in processed_category: return "ì‡¼ë‹¤ìš´í™€ë¤"
    if "ë‰´ë² ê°€ìŠ¤" in processed_category or "newvegas" in processed_category or "ì¹´ì§€ë…¸êµ°" in processed_category: return "ë‰´ë² ê°€ìŠ¤"
    if "ë‰´ë§ê³ " in processed_category or "newmatgo" in processed_category: return "ë‰´ë§ê³ "
    if "ì„¯ë‹¤" in processed_category or "sutda" in processed_category: return "ì„¯ë‹¤"
    if "í¬ì»¤" in processed_category or "poker" in processed_category: return "í¬ì»¤"
    return "ê¸°íƒ€"

def classify_platform(category):
    if pd.isna(category): return "ê¸°íƒ€"
    processed_category = re.sub(r'[^a-z0-9ã„±-ã…ã…-ã…£ê°€-í£]', '', str(category).lower())
    if "forkakao" in processed_category or "fork" in processed_category: return "for kakao"
    if "mob" in processed_category or "ëª¨ë°”ì¼" in processed_category: return "MOB"
    if "pc" in processed_category: return "PC"
    return "ê¸°íƒ€"

def extract_gsn_usn(row):
    platform = row.get('í”Œë«í¼', '')
    if platform in ['MOB', 'for kakao']:
        inquiry_content = str(row.get('ë¬¸ì˜ë‚´ìš©', ''))
        gsn_match = re.search(r'íšŒì›ë²ˆí˜¸\s*:\s*(\d+)', inquiry_content)
        if gsn_match: return gsn_match.group(1)
    if platform == 'PC':
        customer_info = str(row.get('ê³ ê°ì •ë³´', ''))
        usn_match = re.search(r'\d+', customer_info)
        if usn_match: return usn_match.group(0)
    return ""

def extract_device_info(row):
    inquiry_content = str(row.get('ë¬¸ì˜ë‚´ìš©', ''))
    device_match = re.search(r'íœ´ëŒ€í°ê¸°ê¸°ì •ë³´\s*:\s*(\S+)', inquiry_content)
    if device_match: return device_match.group(1)
    platform = row.get('í”Œë«í¼', '')
    if platform == 'PC': return 'PC'
    return ""

def truncate_inquiry_content(text):
    if isinstance(text, str): return text.split("íšŒì›ë²ˆí˜¸ :")[0].strip()
    return ""


@st.cache_data(ttl=600)
def load_data():
    """Google Sheetsì—ì„œ ëª¨ë“  VOC ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    try:
        scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        creds = None
        spreadsheet_id = "1rgR21yUBtKSJKE4KYdBvoZzDU-0jZ_wLb6Tqc_zS7RM" # ê¸°ë³¸ê°’
        
        # [ì˜¤ë¥˜ ìˆ˜ì •] ë°°í¬ í™˜ê²½(st.secrets)ê³¼ ë¡œì»¬ í™˜ê²½(json íŒŒì¼) ëª¨ë‘ ì§€ì›í•˜ë„ë¡ ìˆ˜ì •
        try:
            # ë°°í¬ í™˜ê²½: st.secretsì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ
            creds_dict = dict(st.secrets["gcp_service_account"])
            creds = service_account.Credentials.from_service_account_info(creds_dict, scopes=scopes)
            spreadsheet_id = st.secrets.get("SHEET_ID", spreadsheet_id)
        except (st.errors.StreamlitAPIException, FileNotFoundError, KeyError):
            # ë¡œì»¬ í™˜ê²½: service_account.json íŒŒì¼ì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ
            SERVICE_ACCOUNT_FILE = "service_account.json"
            if os.path.exists(SERVICE_ACCOUNT_FILE):
                creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scopes)
            else:
                st.error(f"ì¸ì¦ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ í´ë”ì— '{SERVICE_ACCOUNT_FILE}' íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
                return pd.DataFrame()

        gc = gspread.authorize(creds)
        
        spreadsheet = gc.open_by_key(spreadsheet_id)
        
        worksheets = spreadsheet.worksheets()
        all_data = []
        for worksheet in worksheets:
            if worksheet.title.lower() not in ["sheet1", "template", "mapping"]:
                try:
                    data = worksheet.get_all_records()
                    if data:
                        for row in data: row["ë‚ ì§œ"] = worksheet.title
                        all_data.extend(data)
                except Exception: continue
        
        if not all_data: return pd.DataFrame()
        df = pd.DataFrame(all_data)
        
        required_cols = ["ì ‘ìˆ˜ ì¹´í…Œê³ ë¦¬", "ìƒë‹´ì œëª©", "ë¬¸ì˜ë‚´ìš©", "taglist"]
        if not all(col in df.columns for col in required_cols):
            st.error(f"í•„ìˆ˜ ì»¬ëŸ¼({required_cols})ì´ Google Sheetsì— ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        df.rename(columns={'taglist': 'L2 íƒœê·¸'}, inplace=True)
        df["ê²Œì„"] = df["ì ‘ìˆ˜ ì¹´í…Œê³ ë¦¬"].apply(classify_game)
        df["í”Œë«í¼"] = df["ì ‘ìˆ˜ ì¹´í…Œê³ ë¦¬"].apply(classify_platform)
        df["ë‚ ì§œ_dt"] = pd.to_datetime(df["ë‚ ì§œ"], format='%y%m%d', errors='coerce')
        df = df.dropna(subset=["ë‚ ì§œ_dt"])
        df['L1 íƒœê·¸'] = df['L2 íƒœê·¸'].map(L2_TO_L1_MAPPING).fillna('ê¸°íƒ€')
        df['GSN(USN)'] = df.apply(extract_gsn_usn, axis=1)
        df['ê¸°ê¸°ì •ë³´'] = df.apply(extract_device_info, axis=1)
        df['ë¬¸ì˜ë‚´ìš©_ìš”ì•½'] = df['ë¬¸ì˜ë‚´ìš©'].apply(truncate_inquiry_content)
        df['ê²€ìƒ‰ìš©_ë¬¸ì˜ë‚´ìš©'] = df['ë¬¸ì˜ë‚´ìš©_ìš”ì•½']
        
        return df

    except gspread.exceptions.SpreadsheetNotFound:
        st.error("Google Sheets ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. SPREADSHEET_IDë¥¼ í™•ì¸í•˜ê±°ë‚˜ Secretsì— ì˜¬ë°”ë¥´ê²Œ ì„¤ì •í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.exception(e)
        return pd.DataFrame()

@st.cache_data(ttl=1800)
def get_game_issue_summary(_game_name, game_data):
    if game_data.empty: return {"title": "ë°ì´í„° ì—†ìŒ", "quote": "í•´ë‹¹ ê¸°ê°„ì— ìˆ˜ì§‘ëœ VOCê°€ ì—†ìŠµë‹ˆë‹¤."}
    simulated_summaries = {
        "ë‰´ë§ê³ ": {"title": "'ë¶€í™œí•˜ê¸°' ê¸°ëŠ¥ UI/UX ë¶ˆë§Œ ì§€ì† ì¦ê°€", "quote": "ë¶€í™œí•˜ê¸° ë²„íŠ¼ìœ„ì¹˜ë¥¼ ë°”ê¿”ì£¼ë˜ì§€ í•´ì•¼ì§€ ê³„ì† ì‹¤ìˆ˜ë¡œ ëˆŒëŸ¬ì„œ êµ¬ìŠ¬ ì°¨ê°ë˜ë„¤ìš”"},
        "ì„¯ë‹¤": {"title": "ì¬í™” ë¶„ë¦¬ ì •ì±…ì— ëŒ€í•œ í˜¼ë€", "quote": "ì„¯ë‹¤ ë¨¸ë‹ˆê°€ í¬ì»¤ ì—ì„œ ì„¯ë‹¤ë¡œ ì˜®ê²¨ê°„ ë‹¤ìŒ í¬ì»¤ ë¨¸ë‹ˆê°€ ìë™ ë³µì‚¬ ëœ ë‹¤ê³  í•˜ì…¨ëŠ”ë° ìë™ ë³µì‚¬ ê¸°ëŠ¥ì´ ì–´ë””ì— ìˆì£ ~? ...ëˆì´ ë‹¤ë¥¸ë° ì™œ ëˆì´ ë‹¤ë¥´ì£ ~?"},
        "í¬ì»¤": {"title": "ì •ê¸°ê²°ì œ(í´ë˜ìŠ¤) í•´ì§€ ë¬¸ì˜ ì¦ê°€", "quote": "ì •ê¸°ê²°ì œ í•´ì§€ ë°©ë²•ì„ ì°¾ê¸° ì–´ë µë‹¤ëŠ” ë¶ˆë§Œê³¼ í™˜ë¶ˆ ìš”ì²­ì´ ì§€ì†ì ìœ¼ë¡œ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤."},
        "ë‰´ë² ê°€ìŠ¤": {"title": "ë¶ˆë²• ê´‘ê³  í•„í„°ë§ ê°•í™” ìš”ì²­", "quote": "ê·¸ë˜ë„ í”¼ë§ ëŒ€ê¸°ì—… ì•„ë‹˜? ê´‘ê³ ê°€ ë¶ˆë²•ê´‘ê³ ê°€ ë‚˜ì˜¤ë‚´ìš” ì˜¨ë¼ì¸ ì¹´ì§€ë…¸ ê°•ì›ëœë“œë¼ë‡¨..."},
        "ì‡¼ë‹¤ìš´í™€ë¤": {"title": "í‹°ì¼“ ì‚¬ìš©ì²˜ ë° ìŠ¤ì¼€ì¤„ ê°œì„  ìš”ì²­", "quote": "10ë§Œì§œë¦¬ ì¿ í°ì€ ì¶œì„ ë³´ìƒìœ¼ë¡œ ì™œ ì£¼ëŠ” ê±°ì—ìš”?ã…‹ã…‹ã…‹ ìƒˆë²½ 4ì‹œ 6ì‹œì—ë§Œ 10ë§Œ í† ë„ˆ ì—´ë©´ì„œã…‹ã…‹ã…‹ã…‹ã…‹"}
    }
    return simulated_summaries.get(_game_name, {"title": "ë¶„ì„ ì •ë³´ ì—†ìŒ", "quote": "-"})

def clean_text_for_wordcloud(text):
    if not isinstance(text, str): return ""
    return re.sub(r'[^ã„±-ã…ã…-ã…£ê°€-í£\s]', '', text)

def classify_sentiment(text):
    if not isinstance(text, str): return "ì¤‘ë¦½"
    positive_keywords = ["ê°ì‚¬í•©ë‹ˆë‹¤", "ì¢‹ì•„ìš”", "ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤", "í•´ê²°", "ê³ ë§™ìŠµë‹ˆë‹¤"]
    negative_keywords = ["ì§œì¦", "ì˜¤ë¥˜", "í™˜ë¶ˆ", "ì•ˆë¼ìš”", "ì“°ë ˆê¸°", "ì¡°ì‘", "ë¶ˆë§Œ", "ë¬¸ì œ", "íŒ¨ëª°ë¦¼", "ì˜¤ë§"]
    text_lower = text.lower()
    if any(keyword in text_lower for keyword in negative_keywords): return "ë¶€ì •"
    if any(keyword in text_lower for keyword in positive_keywords): return "ê¸ì •"
    return "ì¤‘ë¦½"

def generate_wordcloud(text_data):
    cleaned_texts = [clean_text_for_wordcloud(text) for text in text_data]
    text = ' '.join(cleaned_texts)
    if not text.strip():
        st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í‚¤ì›Œë“œê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    font_path_relative = os.path.join('fonts', 'NanumGothic.ttf')
    font_path_windows = 'c:/Windows/Fonts/malgun.ttf'
    font_path = None
    if os.path.exists(font_path_relative): font_path = font_path_relative
    elif os.path.exists(font_path_windows): font_path = font_path_windows
    if font_path:
        korean_stopwords = ['ë¬¸ì˜', 'ê²Œì„', 'í”¼ë§', 'ê³ ê°', 'ë‚´ìš©', 'í™•ì¸', 'ë‹µë³€', 'ë¶€íƒ', 'ì²˜ë¦¬', 'ê´€ë ¨', 'ì•ˆë…•í•˜ì„¸ìš”']
        try:
            wordcloud = WordCloud(font_path=font_path, width=400, height=200, background_color='white', stopwords=set(korean_stopwords)).generate(text)
            fig, ax = plt.subplots(figsize=(4, 2))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)
        except Exception as e: st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        st.warning("ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±ì„ ìœ„í•œ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def mask_phone_number(text):
    if not isinstance(text, str): return text
    return re.sub(r'(010[-.\s]?)\d{3,4}([-.\s]?)\d{4}', r'\1****\2****', text)
    
def create_trend_chart(data, date_range, title):
    start_date, end_date = pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1])
    all_days_in_range = pd.date_range(start=start_date, end=end_date, freq='D')
    range_df = pd.DataFrame(all_days_in_range, columns=['ë‚ ì§œ_dt'])
    daily_counts = data.groupby(data['ë‚ ì§œ_dt'].dt.date).size().reset_index(name="ê±´ìˆ˜")
    daily_counts['ë‚ ì§œ_dt'] = pd.to_datetime(daily_counts['ë‚ ì§œ_dt'])
    merged_data = pd.merge(range_df, daily_counts, on='ë‚ ì§œ_dt', how='left').fillna(0)
    merged_data['ê±´ìˆ˜'] = merged_data['ê±´ìˆ˜'].astype(int)
    fig = px.line(merged_data, x='ë‚ ì§œ_dt', y='ê±´ìˆ˜', title=f"<b>{title}</b>", labels={'ë‚ ì§œ_dt': 'ë‚ ì§œ', 'ê±´ìˆ˜': 'VOC ê±´ìˆ˜'}, markers=True, text="ê±´ìˆ˜")
    fig.update_traces(textposition="top center")
    fig.update_layout(xaxis_title="", yaxis_title="ê±´ìˆ˜", height=300)
    return fig

def create_donut_chart(data, title):
    category_counts = data['L2 íƒœê·¸'].value_counts()
    if len(category_counts) > 5:
        top_4 = category_counts.nlargest(4)
        others_count = category_counts.iloc[4:].sum()
        chart_data = top_4._append(pd.Series([others_count], index=['ê¸°íƒ€']))
    else: chart_data = category_counts
    fig = go.Figure(data=[go.Pie(labels=chart_data.index, values=chart_data.values, hole=.6, textinfo='label+percent', insidetextorientation='radial')])
    fig.update_layout(title_text=f"<b>{title}</b>", showlegend=False, height=300, margin=dict(l=20, r=20, t=60, b=20))
    return fig

def get_image_as_base64(path):
    if os.path.exists(path):
        with open(path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode()
    return None

# --- 3. UI êµ¬ì„± ---
logo_base64 = get_image_as_base64(LOGO_IMAGE)
if logo_base64:
    st.markdown(f"""<div style="display: flex; align-items: center; margin-bottom: 20px;"><img src="data:image/png;base64,{logo_base64}" width="200" style="margin-right: 15px;"><h1 style="margin: 0; font-size: 2.5rem;">ì›¹ë³´ë“œ VOC ëŒ€ì‹œë³´ë“œ</h1></div>""", unsafe_allow_html=True)
else: st.title("ğŸ“Š ì›¹ë³´ë“œ VOC ëŒ€ì‹œë³´ë“œ")

st.markdown("""<style> ... </style>""", unsafe_allow_html=True) # ê¸°ì¡´ CSS ì½”ë“œëŠ” ê¸¸ì–´ì„œ ìƒëµ

st.markdown("---")
voc_data = load_data()
if voc_data.empty: st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Google Sheetsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    # --- (ì´í•˜ ëª¨ë“  UI ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼) ---
    with st.sidebar:
        st.title("ğŸ’» VOC ëŒ€ì‹œë³´ë“œ")
        st.markdown("### ğŸ•¹ï¸ ê²Œì„ ë° í”Œë«í¼ ì„ íƒ")
        game_filters = {
            "ë‰´ë§ê³ ": ["ë‰´ë§ê³  (ì „ì²´)", "ë‰´ë§ê³  MOB", "ë‰´ë§ê³  PC", "ë‰´ë§ê³  for kakao"],
            "ì„¯ë‹¤": ["ì„¯ë‹¤ (ì „ì²´)", "ì„¯ë‹¤ MOB", "ì„¯ë‹¤ PC", "ì„¯ë‹¤ for kakao"],
            "í¬ì»¤": ["í¬ì»¤ (ì „ì²´)", "í¬ì»¤ MOB", "í¬ì»¤ PC", "í¬ì»¤ for kakao"],
            "ì‡¼ë‹¤ìš´í™€ë¤": ["ì‡¼ë‹¤ìš´í™€ë¤ (ì „ì²´)", "ì‡¼ë‹¤ìš´í™€ë¤ MOB", "ì‡¼ë‹¤ìš´í™€ë¤ PC"],
            "ë‰´ë² ê°€ìŠ¤": ["ë‰´ë² ê°€ìŠ¤ (ì „ì²´)", "ë‰´ë² ê°€ìŠ¤ MOB", "ë‰´ë² ê°€ìŠ¤ PC"],
            "ê¸°íƒ€": ["ê¸°íƒ€"]
        }
        all_options_with_groups = [opt for sublist in game_filters.values() for opt in sublist]
        all_child_options = [opt for game, opts in game_filters.items() for opt in (opts[1:] if "(ì „ì²´)" in opts[0] else opts)]
        
        def master_checkbox_callback():
            is_all_selected = st.session_state.get('select_all', False)
            for option in all_options_with_groups:
                st.session_state[option] = is_all_selected

        def group_checkbox_callback(game_key):
            is_group_selected = st.session_state.get(f"{game_key} (ì „ì²´)", False)
            for option in game_filters[game_key][1:]:
                st.session_state[option] = is_group_selected
            update_master_checkbox()

        def child_checkbox_callback(game_key):
            if len(game_filters[game_key]) > 1:
                all_children_selected = all(st.session_state.get(opt, False) for opt in game_filters[game_key][1:])
                st.session_state[f"{game_key} (ì „ì²´)"] = all_children_selected
            update_master_checkbox()

        def update_master_checkbox():
            all_groups_selected = all(st.session_state.get(f"{game} (ì „ì²´)", False) for game, opts in game_filters.items() if len(opts) > 1 and "(ì „ì²´)" in opts[0])
            all_single_games_selected = all(st.session_state.get(opts[0], False) for game, opts in game_filters.items() if len(opts) == 1)
            st.session_state.select_all = all_groups_selected and all_single_games_selected
        
        if 'filters_initialized' not in st.session_state:
            st.session_state.filters_initialized = True
            st.session_state.select_all = True
            for option in all_options_with_groups:
                st.session_state[option] = True
        
        st.checkbox("ì „ì²´", key='select_all', on_change=master_checkbox_callback)

        for game, options in game_filters.items():
            with st.expander(game, expanded=True):
                if len(options) > 1 and "(ì „ì²´)" in options[0]:
                    st.checkbox(options[0], key=options[0], on_change=group_checkbox_callback, args=(game,))
                    for option in options[1:]:
                        st.checkbox(option, key=option, on_change=child_checkbox_callback, args=(game,))
                else:
                    st.checkbox(options[0], key=options[0], on_change=update_master_checkbox)

        selected_options = [option for option in all_child_options if st.session_state.get(option, False)]
        
    if not selected_options:
        game_filtered_data = pd.DataFrame()
    else:
        conditions = []
        for option in selected_options:
            if " for kakao" in option:
                game_name = option.replace(" for kakao", "")
                platform_name = "for kakao"
                conditions.append((voc_data['ê²Œì„'] == game_name) & (voc_data['í”Œë«í¼'] == platform_name))
            else:
                parts = option.rsplit(" ", 1)
                game_name = parts[0]
                platform_name = parts[1] if len(parts) > 1 else None

                if platform_name:
                    conditions.append((voc_data['ê²Œì„'] == game_name) & (voc_data['í”Œë«í¼'] == platform_name))
                else: 
                    conditions.append(voc_data['ê²Œì„'] == game_name)

        if conditions:
            final_condition = pd.concat(conditions, axis=1).any(axis=1)
            game_filtered_data = voc_data[final_condition].copy()
        else:
            game_filtered_data = pd.DataFrame()
            
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ğŸ“… ê¸°ê°„ ì„ íƒ")
        
        if game_filtered_data.empty:
            st.warning("ì„ íƒëœ ê²Œì„/í”Œë«í¼ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            date_range = (datetime.now().date() - timedelta(days=6), datetime.now().date())
        else:
            min_date_for_filter = game_filtered_data['ë‚ ì§œ_dt'].min().date()
            max_date_for_filter = game_filtered_data['ë‚ ì§œ_dt'].max().date()

            def set_date_range(days):
                start = max_date_for_filter - timedelta(days=days-1)
                if start < min_date_for_filter:
                    start = min_date_for_filter
                st.session_state.date_range = (start, max_date_for_filter)

            col1, col2 = st.columns(2)
            with col1: st.button("ìµœê·¼ 7ì¼", on_click=set_date_range, args=(7,), use_container_width=True)
            with col2: st.button("ìµœê·¼ 30ì¼", on_click=set_date_range, args=(30,), use_container_width=True)

            if 'date_range' not in st.session_state:
                set_date_range(7)
            else:
                if isinstance(st.session_state.date_range, (list, tuple)) and len(st.session_state.date_range) == 2:
                    start_state, end_state = st.session_state.date_range
                    start_state = max(start_state, min_date_for_filter)
                    end_state = min(end_state, max_date_for_filter)
                    if start_state > end_state:
                        start_state = end_state
                    st.session_state.date_range = (start_state, end_state)
                else:
                    set_date_range(7)

            date_range = st.date_input("ì¡°íšŒ ê¸°ê°„:", key='date_range', min_value=min_date_for_filter, max_value=max_date_for_filter)

    if game_filtered_data.empty or len(date_range) != 2:
        filtered_data = pd.DataFrame()
    else:
        start_date = pd.to_datetime(date_range[0])
        end_date = pd.to_datetime(date_range[1])
        filtered_data = game_filtered_data[(game_filtered_data["ë‚ ì§œ_dt"] >= start_date) & (game_filtered_data["ë‚ ì§œ_dt"] <= end_date)].copy()

    if filtered_data.empty:
        st.warning(f"ì„ íƒí•˜ì‹  ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” VOC ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        with st.container(border=True):
            st.header("ğŸš€ í•µì‹¬ ì§€í‘œ ìš”ì•½")
            st.markdown(f"**ê¸°ê°„: {date_range[0].strftime('%Y-%m-%d')} ~ {date_range[1].strftime('%Y-%m-%d')}**")
            
            current_count = len(filtered_data)
            period_days = (date_range[1] - date_range[0]).days + 1
            prev_start_date = date_range[0] - timedelta(days=period_days)
            prev_end_date = date_range[1] - timedelta(days=period_days)
            prev_period_data = game_filtered_data[(game_filtered_data["ë‚ ì§œ_dt"] >= pd.to_datetime(prev_start_date)) & (game_filtered_data["ë‚ ì§œ_dt"] <= pd.to_datetime(prev_end_date))]
            prev_count = len(prev_period_data)
            delta = current_count - prev_count
            
            col1, col2 = st.columns([1, 2])
            with col1:
                delta_text = f"{delta} ê±´ (ì´ì „ ë™ì¼ ê¸°ê°„ ëŒ€ë¹„)"
                st.metric("ì´ VOC ê±´ìˆ˜", f"{current_count} ê±´", delta_text, help=f"ì´ì „ ê¸°ê°„: {prev_start_date.strftime('%Y-%m-%d')}~{prev_end_date.strftime('%Y-%m-%d')}")
            
            with col2:
                fig_donut = create_donut_chart(filtered_data, "ì£¼ìš” ì¹´í…Œê³ ë¦¬ TOP 5")
                st.plotly_chart(fig_donut, use_container_width=True)
            
            st.markdown("---")
            st.subheader("ğŸ‘ª ê²Œì„ë³„ ì£¼ìš” ë™í–¥ (AI ìš”ì•½)")
            st.info("ì•„ë˜ ë‚´ìš©ì€ ì„ íƒëœ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ë™ì ìœ¼ë¡œ ìƒì„±í•œ ìš”ì•½ì…ë‹ˆë‹¤. (í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜)")

            game_list_for_summary = ["ë‰´ë§ê³ ", "ì„¯ë‹¤", "í¬ì»¤", "ë‰´ë² ê°€ìŠ¤", "ì‡¼ë‹¤ìš´í™€ë¤"]
            game_icons = {"ë‰´ë§ê³ ": "ğŸ´", "ì„¯ë‹¤": "ğŸ´", "í¬ì»¤": "â™£ï¸", "ë‰´ë² ê°€ìŠ¤": "ğŸ°", "ì‡¼ë‹¤ìš´í™€ë¤": "â™ ï¸"}
            
            issue_cols = st.columns(5)
            for i, game_name in enumerate(game_list_for_summary):
                with issue_cols[i]:
                    game_data = filtered_data[filtered_data['ê²Œì„'] == game_name]
                    summary = get_game_issue_summary(game_name, game_data)
                    st.markdown(f"""<div class="issue-card"><h5>{game_icons.get(game_name, "ğŸƒ")} {game_name}</h5><p><strong>{summary['title']}</strong></p><blockquote style="font-size: 0.9rem; color: #6c757d;">"{summary['quote']}"</blockquote></div>""", unsafe_allow_html=True)

        st.markdown("---")
        
        tab_main, tab_search = st.tabs(["### ğŸ“Š ì¹´í…Œê³ ë¦¬ ë¶„ì„", "### ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰"])
        
        with tab_main:
            col1, col2 = st.columns(2)
            with col1:
                with st.container(border=True):
                    fig_daily_trend = create_trend_chart(filtered_data, date_range, f"ì¼ìë³„ VOC ë°œìƒ ì¶”ì´")
                    st.plotly_chart(fig_daily_trend, use_container_width=True)
            with col2:
                with st.container(border=True):
                    l2_counts = filtered_data['L2 íƒœê·¸'].value_counts().nlargest(10).sort_values(ascending=True)
                    fig_l2 = px.bar(l2_counts, x=l2_counts.values, y=l2_counts.index, orientation='h', title="<b>íƒœê·¸ë³„ í˜„í™© TOP 10</b>", labels={'x': 'ê±´ìˆ˜', 'y': 'íƒœê·¸'}, text_auto=True)
                    fig_l2.update_layout(height=300)
                    st.plotly_chart(fig_l2, use_container_width=True)
            
            st.write("") 

            with st.container(border=True):
                st.header("ğŸ“‘ VOC ì›ë³¸ ë°ì´í„°")
                col1, col2 = st.columns([3, 1])
                with col1:
                    top5_categories = filtered_data['L2 íƒœê·¸'].value_counts().nlargest(5)
                    all_categories = sorted(filtered_data['L2 íƒœê·¸'].unique())
                    selected_categories = st.multiselect("í™•ì¸í•˜ê³  ì‹¶ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:", options=all_categories, default=top5_categories.index.tolist())
                
                if selected_categories:
                    display_data = filtered_data[filtered_data['L2 íƒœê·¸'].isin(selected_categories)].copy()
                    with col2:
                        st.text(" ") 
                        st.download_button(label="ğŸ“¥ CSVë¡œ ë‹¤ìš´ë¡œë“œ", data=display_data.to_csv(index=False).encode('utf-8-sig'), file_name=f"voc_category_data_{datetime.now().strftime('%Y%m%d')}.csv", mime="text/csv", use_container_width=True)
                    display_data['ë¬¸ì˜ë‚´ìš©_ìš”ì•½'] = display_data['ë¬¸ì˜ë‚´ìš©_ìš”ì•½'].apply(mask_phone_number)
                    display_df = display_data.rename(columns={'í”Œë«í¼': 'êµ¬ë¶„', 'ë¬¸ì˜ë‚´ìš©_ìš”ì•½': 'ë¬¸ì˜ ë‚´ìš©'})
                    st.dataframe(display_df[["êµ¬ë¶„", "ë‚ ì§œ", "ê²Œì„", "L2 íƒœê·¸", "ìƒë‹´ì œëª©", "ë¬¸ì˜ ë‚´ìš©", "GSN(USN)", "ê¸°ê¸°ì •ë³´"]], use_container_width=True, height=500)

        with tab_search:
            st.header("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰")
            
            col1, col2 = st.columns([5, 1])
            with col1:
                search_keyword = st.text_input("ê²€ìƒ‰í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: í™˜ë¶ˆ, íŠ•ê¹€, ì—…ë°ì´íŠ¸...")
            with col2:
                st.write(" ")
                st.button("ê²€ìƒ‰", use_container_width=True)

            if search_keyword:
                search_results = filtered_data[filtered_data["ìƒë‹´ì œëª©"].str.contains(search_keyword, na=False, case=False) | filtered_data["ê²€ìƒ‰ìš©_ë¬¸ì˜ë‚´ìš©"].str.contains(search_keyword, na=False, case=False)].copy()
                if not search_results.empty:
                    st.success(f"âœ… \"{search_keyword}\" í‚¤ì›Œë“œê°€ í¬í•¨ëœ VOC: **{len(search_results)}**ê±´")
                    
                    search_results['ê°ì„±'] = search_results['ë¬¸ì˜ë‚´ìš©'].apply(classify_sentiment)

                    with st.container(border=True):
                        st.header(f"'{search_keyword}' í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ì´")
                        fig_search_trend = create_trend_chart(search_results, date_range, f"'{search_keyword}' í‚¤ì›Œë“œ ì¼ìë³„ ë°œìƒ ì¶”ì´")
                        st.plotly_chart(fig_search_trend, use_container_width=True)

                    with st.container(border=True):
                        st.header("ê´€ë ¨ VOC ëª©ë¡")
                        st.download_button(label="ğŸ“¥ ê²€ìƒ‰ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", data=search_results.to_csv(index=False).encode('utf-8-sig'), file_name=f"voc_search_{search_keyword}_{datetime.now().strftime('%Y%m%d')}.csv", mime="text/csv")
                        search_results['ë¬¸ì˜ë‚´ìš©_ìš”ì•½'] = search_results['ë¬¸ì˜ë‚´ìš©_ìš”ì•½'].apply(mask_phone_number)
                        display_search_df = search_results.rename(columns={'í”Œë«í¼': 'êµ¬ë¶„', 'ë¬¸ì˜ë‚´ìš©_ìš”ì•½': 'ë¬¸ì˜ ë‚´ìš©'})
                        st.dataframe(display_search_df[["êµ¬ë¶„", "ë‚ ì§œ", "ê²Œì„", "L2 íƒœê·¸", "ìƒë‹´ì œëª©", "ë¬¸ì˜ ë‚´ìš©", "GSN(USN)", "ê¸°ê¸°ì •ë³´", "ê°ì„±"]], use_container_width=True, height=400)

                    st.write("") 
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        with st.container(border=True):
                            st.header("ê°ì„± ë¶„ì„ ê²°ê³¼")
                            sentiment_counts = search_results['ê°ì„±'].value_counts()
                            sentiment_cols = st.columns(3)
                            sentiment_cols[0].metric("ê¸ì • ğŸ˜Š", f"{sentiment_counts.get('ê¸ì •', 0)} ê±´")
                            sentiment_cols[1].metric("ë¶€ì • ğŸ˜ ", f"{sentiment_counts.get('ë¶€ì •', 0)} ê±´")
                            sentiment_cols[2].metric("ì¤‘ë¦½ ğŸ˜", f"{sentiment_counts.get('ì¤‘ë¦½', 0)} ê±´")
                    with col2:
                        with st.container(border=True):
                            st.header("ì—°ê´€ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
                            generate_wordcloud(search_results["ë¬¸ì˜ë‚´ìš©"])

                else:
                    st.warning(f"âš ï¸ \"{search_keyword}\" í‚¤ì›Œë“œê°€ í¬í•¨ëœ VOCê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")
    logo_base64 = get_image_as_base64(LOGO_IMAGE)
    if logo_base64:
        footer_html = f"""<div style="text-align: center; padding-top: 20px; padding-bottom: 20px;"><img src="data:image/png;base64,{logo_base64}" width="100"><p style="font-size: 0.8rem; color: #6c757d; margin-top: 10px;">Â© NEOWIZ Corp. All Rights Reserved.</p></div>"""
        st.markdown(footer_html, unsafe_allow_html=True)

